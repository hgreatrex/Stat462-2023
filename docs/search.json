[
  {
    "objectID": "in_S462_Project04FinalUPDATED.html",
    "href": "in_S462_Project04FinalUPDATED.html",
    "title": "4. Final Project Report UPDATED CODE",
    "section": "",
    "text": "THIS CONTAINS MORE SOPHISTICATED CODE THAT DOES THE SAME JOB BUT LOOKS BETTER\nIn this page there is:\n\nAbout the report\nWhat to submit/format\nWhat content to include\nThe grading rubric/checklist\nThe final dataset, useful code and things we have learned this semester\n\n\n\n1. About\nCANVAS PAGE HERE: https://psu.instructure.com/courses/2243429/assignments/15012915\nCongratulations! You made it to the end of the semester. Thanks for being awesome\nOver the last few weeks, we have been working on analyzing and modelling the temperature data. Your job is now to put it all together using the code we have used.\nYou can EITHER\n\nWork in groups, where you clearly show what each team member contributes. In this case,I expect at least one or two models by each group member and a comparison of their pros and cons.\nor individually (attributing any early work created by another team member)\n\nThis is worth 50 points. I am grading you on the thoughtfulness and quality of your analysis.There is no “right” answer.\n\n\n2. What to submit, report format\nA .Rmd and a .html file containing your report\nTo get an A grade, I expect professional formatting, tables of contents, templates, extraneous “welcome” text removed from package loading using code chunk options. Use the templates from previous labs/reports!\n\n\n3. Content to include\nRemember you can use text/figures/analysis from throughout the semester and from all the project discussion boards.\n\nA introduction about the climate of State College (esp the temperature) - remember Weather Spark!\n\nTo clearly state the aim of the project, which is to predict the coldest location in State College TOWNSHIP, given the calibration data which was placed over the entire area.\n\nTo talk about what might cause temperature differences, using your causal flowcharts.\n\nTo clearly state the object of analysis of the calibration data, and the predictor variables, along with any quality control and data wrangling we have done (it’s OK to talk more generally about the Quality Control rather than every specific sensor removed etc). Remember units! All described with sources here - https://psu-spatial.github.io/Stat462-2023/in_S462_Project03InitialEDA.html\n\nTo create a series of models, check their validity (LINE), discuss the goodness of fit and describe your favorite. Useful code below.\n\nTo decide on your final object of analysis, response variable and predictors, then use that model to predict the location of the coldest temperature on Monday 1st May. Remember you can use the forecast temperature for the future airport temperature! If you can’t make a complex model work for prediction, tell me and then choose an easier one\n\nFor 10 bonus points, to collect a temp sensor from me in Walker 201 in office hours tomorrow, or in Friday’s lecture. Then put it out in your predicted location, recording the Lat/Long and taking some photos & filling in the google form, then bringing back the sensor by the exam. We will see who is correct!\n\nThis is not part of the main report & you do not have to talk about the results as it will take me a week to find out the results.\n\n\n\n4. Grading Rubric/checklist\nSee the table below for what this means - 100% is hard to get!\nThe text below shows what I would expect from such a report.\n\nHTML/RMD FILE SUBMISSION - 5 marks\n\n\nFORMAT/PROFESSIONAL REPORT - 10 MARKS\n\nFull marks for a report that I would take into a job interview. You lose marks for each thing that makes it look non-professional.\nI AM NOT GRADING GRAMMAR ETC. I know some people speak English as a second language. This is not a writing class.\nYou have done things like fully labeled plots, used mathematical equation formats, sub-headings, used spell check, a theme and as relevant things like tables of contents. You have used photos/pictures as appropriate. You included units and used code chunk options to hide any spurious code output.\nIn the text, you have written full paragraphs/sentences, explained results in clear language ON THE TOPIC OF TEMPERATURE (e.g.. beyond “reject H0” you have described what this means)\n\n\n\nGRAPHICS - 5 MARKS\n\nYou have included maps, summary statistics and scatterplots as appropriate. Your plots look great with professional axes labels and colors. You have tried more sophisticated plots than just the basics (remember ggstatplot!),\n\n\n\nINTRODUCTION/DESCRIPTION/QUALITY CONTROL - 10 MARKS.\n\nYou have thoughtfully described the problem, correctly identifying the object/variables AND units! You have explored the causal chain & quality control and it’s clear why you’re choosing your final models.\n\n\n\nMODELLING - 10 MARKS\n\nYou created your model correctly and explained why you chose them. In your write up you have summarised the model equation (including the coefficients as numbers) & summarising units afterwards. You have produced a model summary, assessed LINE/outliers and answered all questions as appropriate. It is likely that you used some sort of model selection tool such as Best SubSets.\n\n\n\nPREDICTION - 10 MARKS\n\nYou have decided on your final model, explained why, checked its validity and used the output map to decide where to put your sensor.\nNote, the final prediction is a grid cell! So you should also describe where inside your chosen grid square you will place your sensor (e.g. not in the middle of the I80 or a private house…)\n\n[50 marks total]\nWithin each section above, I am using this “sub-rubric”\n\n\n\n\n \n  \n    Grade \n    % Mark \n    Rubric \n  \n \n\n  \n    A* \n    98-100 \n    Exceptional.  Not only was it near perfect, but the graders learned something.  THIS IS HARD TO GET. \n  \n  \n    NA \n    96+ \n    You went above and beyond \n  \n  \n    A \n    94+: \n    Everything asked for with high quality.   Class example \n  \n  \n    A- \n    90+ \n    The odd minor mistake, All code done but not written up in full sentences etc. A little less care \n  \n  \n    B+ \n    87+ \n    More minor mistakes.  Things like missing units, getting the odd question wrong, no workings shown \n  \n  \n    B \n    84+ \n    Solid work but the odd larger mistake or missing answer.  Completely misinterpreted something, that type of thing \n  \n  \n    B- \n    80+ \n    Starting to miss entire/questions sections, or multiple larger mistakes. Still a solid attempt.  \n  \n  \n    C+ \n    77+ \n    You made a good effort and did some things well, but there were a lot of problems. (e.g. you wrote up the text well, but messed up the code) \n  \n  \n    C \n    70+ \n    It’s clear you tried and learned something.  Just attending labs will get you this much as we can help you get to this stage \n  \n  \n    D \n    60+ \n    You attempt the lab and submit something. Not clear you put in much effort or you had real issues \n  \n  \n    F \n    0+ \n    Didn’t submit, or incredibly limited attempt.  \n  \n\n\n\n\n\n\n\n\n5. Data and useful code\n\nA. Set-up\n1st, I strongly suggest using a theme and using an R project. See the earlier tutorials for more.\nAlso a code chunk at the top, where you can put “include=FALSE” in the code chunk options to hide it. This will remove spurious messages. More info here if you don’t know what I mean: https://rmarkdown.rstudio.com/lesson-3.html\n\n## Global options\nrm(list=ls())\nknitr::opts_chunk$set(cache = TRUE,message=FALSE,warning=FALSE)\n\nThese libraries might be useful.\n\n# Load libraries\nlibrary(\"tidyverse\") # Lots of data processing commands\nlibrary(\"knitr\")     # Helps make good output files\nlibrary(\"ggplot2\")   # Output plots\nlibrary(\"rmarkdown\") # Helps make good output files\nlibrary(\"lattice\")   # Makes nice plots\nlibrary(\"RColorBrewer\") # Makes nice color-scales\nlibrary(\"skimr\")     # Summary statistics\nlibrary(\"Stat2Data\") # Regression specific commands\nlibrary(\"corrplot\")  # correlation plots\nlibrary(\"GGally\")    # correlation plots\nlibrary(\"ggpubr\")    # QQplots\nlibrary(\"olsrr\")     # Regression specific commands\nlibrary(\"plotly\")    # Interactive plots\nlibrary(\"readxl\")    # Read from excel files\nlibrary(\"equatiomatic\") # extract equations\nlibrary(\"ggstatsplot\") # Make nice plots\nlibrary(\"visreg\") #visualise regression outputs\nlibrary(\"MASS\") # Studentised residuals\nlibrary(\"terra\") # Spatial\nlibrary(\"sf\") # Spatial\nlibrary(\"sp\")  # Spatial\nlibrary(\"tmap\") # Spatial\nlibrary(\"raster\") # Spatial\nlibrary(\"kableExtra\") # if you want to make fancy tables\n\n\n\nB. Final Calibration Dataset\nYou can download the final calibration dataset here.\nThis is the SAME as last week and is in Project Assignment 7 MLR,\nPut the data into your project library. If I update the dataset, I will update exactly with the same filenames so you can overwrite\n\n\nC. Reading in the data\nHere is how I read in the calibration and prediction data. Units below the code\nIf you wish to understand the map projection part and why the location is X and Y in metres rather than Long/Lat, see this tutorial. You can read more about the specific projection I chose here, https://epsg.io/32617 (it’s UTM).\n\n#------------------------------------------------------------------------\n# CLEAR THE WORKSPACE\n#------------------------------------------------------------------------\n rm(list=ls())\n\n#------------------------------------------------------------------------\n# LOAD SPATIAL BORDERS\n#------------------------------------------------------------------------\n MyMapProjection <- \"EPSG:32617\" #UTM17\n TrainingBorder <- st_read(\"TrainingArea.shp\",crs=MyMapProjection)\n predictBorder  <- st_read(\"PredictionBorder.shp\",crs=MyMapProjection)\n\n#------------------------------------------------------------------------\n# LOAD TRAINING DATA\n#------------------------------------------------------------------------ \n TrainingData <- read_excel(\"FinalMidnightData.xlsx\")\n TrainingData$TownshipName <- as.factor(TrainingData$TownshipName)\n TrainingData.sf  <- st_as_sf(TrainingData,crs=MyMapProjection, coords=c(\"X\",\"Y\"))\n\n#------------------------------------------------------------------------\n# LOAD PREDICTON DATA\n#------------------------------------------------------------------------\n PredictionData <- rast(\"PredictionRaster.tif\")\n\n # Set the map projection.\n crs(PredictionData) <- MyMapProjection\n\n # Rename so it exactly matches the model. For units & sources, see \n names(PredictionData) <- c(\"Elevation\",\n                            \"Slope\",\n                            \"Roughness\",\n                            \"Aspect\",\n                            \"LandCover_Code\",\n                            \"NCLD_Percent_Tree_Cover\",\n                            \"NCLD_Percent_Concrete\" )\n\n # Add in the additional columns\n PredictionData$Serial       <- NA # or replace with your sensor's serial number\n PredictionData$Date         <- \"2023-05-01\"\n PredictionData$Hour         <- TrainingData$Hour[1]\n PredictionData$Minute       <- TrainingData$Minute[1]\n PredictionData$TownshipName <- as.factor(\"State College\")\n PredictionData$Light_Lux    <- 0\n PredictionData$X  <- xyFromCell(PredictionData, 1:ncell(PredictionData))[,1]\n PredictionData$Y  <- xyFromCell(PredictionData, 1:ncell(PredictionData))[,2]\n\n # YOU NEED TO MODIFY THESE!\n # Change the NA to the forecast weather conditions at the airport at midnight on May-1 \n PredictionData$AirportTemp     <- NA # Unit:F\n PredictionData$AirportPressure <- NA # Unit:mbar\n PredictionData$AirportWind     <- NA # Unit: mph\n PredictionData$AirportDir      <- NA # Unit: degrees\n # Hint, see weather underground/accuweather , \n # or https://forecast.weather.gov/MapClick.php?lat=40.85344&lon=-77.8401\n \n # Both Predict.df and PredictionData are now identical so your code should still run.\n Predict.df <- PredictionData\n\n\nC.1 Units/Sources for the data.\n\nSerial: the serial number of the sensor\nX and Y. The location of the sensor/predicted point in X and Y metre coordinates\n\nNote, Long/Lat coordinates are poor over small areas, so I’m using the WGS84 17N / Pennsylvania North map projection (https://epsg.io/32617). If you wish to understand more, see this tutorial.\n\nElevation_1m: The elevation of the sensor/predicted point to the closest metre from the USGS 1 meter Digital Elevation Model (https://data.usgs.gov/datacatalog/data/USGS:77ae0551-c61e-4979-aedd-d797abdcde0e). I also added in sensor height off the ground\nSlope_1m : The slope of the location where the sensor was placed, from the same USGS DEM\nAspect_1m : The aspect of the location where the sensor was placed., from the same USGS DEM\nRoughness_1m : The roughness of the location where the sensor was placed, from the same USGS DEM\nLandCover_Code: The NCLD landcover code for that location, from here https://www.mrlc.gov/data/legends/national-land-cover-database-class-legend-and-description and automatically downloaded using the FedData package\nNCLD_Percent_Tree_Cover: The percent tree cover for that location from the same NCLD database\nNCLD_Percent_Concrete : The percent concrete at that location from the same NCLD database\nDate: Date of the measurement in yyyy-mm-dd\nHour: Hour of the measurement - should all be at midnight\nTemp_F: Unit F. The temperature measurement in F at each training sensor. #\nLight_Lux: Unit Lux, The Light measurement at each training sensor. I assumed for prediction that the lux would be 0 (e.g it’s dark at midnight)\nAirportTemp Unit: F. This is the temperature at University Park weather station at midnight on each day we took data. (source - http://www.climate.psu.edu/data/ida/index.php?t=3&x=faa_hourly&id=KUNV)\n\nFor prediction YOU NEED TO PREDICT WHAT THIS WILL BE AT MIDNIGHT ON THE 1ST MAY\n\nAirportPressure Unit - mbar: This is the pressure at University Park weather station at midnight on each day. High pressure normally means sunny/warm. Low pressure means rain/cloud. (source - http://www.climate.psu.edu/data/ida/index.php?t=3&x=faa_hourly&id=KUNV)\n\nFor prediction YOU NEED TO PREDICT WHAT THIS WILL BE AT MIDNIGHT ON THE 1ST MAY\n\nAirportWind : Unit, mph. This is the windspeed at University Park weather station at midnight on each day. (source - http://www.climate.psu.edu/data/ida/index.php?t=3&x=faa_hourly&id=KUNV)\n\nFor prediction YOU NEED TO PREDICT WHAT THIS WILL BE AT MIDNIGHT ON THE 1ST MAY\n\nAirportWindDir : Unit, degrees. This is the degree angle that the wind is blowing from at the airport. E.g. 0/360 means from the north, 90 means from the west etc.(source - http://www.climate.psu.edu/data/ida/index.php?t=3&x=faa_hourly&id=KUNV)\n\nFor prediction YOU NEED TO PREDICT WHAT THIS WILL BE AT MIDNIGHT ON THE 1ST MAY\n\n\n\n\n\nD. Making maps of predictors\nIt is now very easy to make maps of your predictors. Each predictor has the same column name as the training data, type this to see them\n\nnames(PredictionData)\n\nThis makes four maps of four variables, adds in the locations of the training data and the prediction data in a few color schemes, then plots them together. Play with this all you like to make it unique :)\n\n# This loads elevation, makes a map with transparency 0.7\n# then adds borders and the training data. It saves it as Map_Elev\n# which I then print using tmap_arrange\n\nMap_Elev <- tm_shape(PredictionData$Elevation) + \n                tm_raster(palette=terrain.colors(99),alpha=0.7, style=\"cont\",) + \n            tm_shape(TrainingBorder) + tm_borders() +\n            tm_shape(predictBorder)  + tm_borders(col=\"black\") +  \n            tm_shape(TrainingData.sf) + tm_dots()\n\nMap_Green <- tm_shape(PredictionData$NCLD_Percent_Tree_Cover) + \n                tm_raster(palette=brewer.pal(7,\"Greens\"),style=\"cont\") + \n            tm_shape(TrainingBorder) + tm_borders() +\n            tm_shape(predictBorder)  + tm_borders(col=\"black\") +  \n            tm_shape(TrainingData.sf) + tm_dots()\n\nMap_Grey <- tm_shape(PredictionData$NCLD_Percent_Concrete) + \n                tm_raster(palette=brewer.pal(7,\"Greys\"),style=\"cont\") + \n            tm_shape(TrainingBorder) + tm_borders() +\n            tm_shape(predictBorder)  + tm_borders(col=\"black\") +  \n            tm_shape(TrainingData.sf) + tm_dots()\n\nMap_Rough <- tm_shape(PredictionData$Roughness) + \n                tm_raster(palette=brewer.pal(7,\"PiYG\"),style=\"cont\") + \n            tm_shape(TrainingBorder) + tm_borders() +\n            tm_shape(predictBorder)  + tm_borders(col=\"black\") +  \n            tm_shape(TrainingData.sf) + tm_dots()\n\n\n\n# Then arrange them together\n# You can choose between static maps \ntmap_mode(\"plot\")\ntmap_arrange(Map_Elev,Map_Green,Map_Grey,Map_Rough)\n\n\n\nrm(Map_Elev);rm(Map_Green);rm(Map_Grey);rm(Map_Rough)\n\n\n\nF. Linear model code\nFor each new model, I normally copy/paste this code and change the model name. I will award bonus points for anyone who makes this into a function.\n\nMaking the model\n\n# Make the model\nModel1 <- lm(Temp_F ~ X + Y + Elevation, data=TrainingData)\n\n# Model summary or summary(Model1)\nols_regress(Model1)\n\n\n\nExtracting the equation\nEither copy/paste this output into the text, or in the code chunk options, put {r, asis=TRUE} for it to automatically show up when it knits.\nFor example this code\n\n# Either type out or use this code to get the equation\nequatiomatic::extract_eq(Model1,coef_digits = 5, use_coefs=TRUE)\n\nbecomes\n\n# Either type out or use this code to get the equation\nequatiomatic::extract_eq(Model1,coef_digits = 5, use_coefs=TRUE)\n\n\\[\n\\operatorname{\\widehat{Temp\\_F}} = 921.75558 + 0.00174(\\operatorname{X}) - 5e-04(\\operatorname{Y}) + 0.10327(\\operatorname{Elevation})\n\\]\n\n\n\n\nChecking assumptions\nI normally put this stuff in a new code chunk or the ols-summary doesn’t show up properly above\n\n# Plot the residuals.  Check linearity and equal variance. \nols_plot_resid_fit(Model1)\nols_plot_resid_stud(Model1)\nols_plot_resid_stand(Model1)\n\n# Check normality\nols_plot_resid_hist(Model1)\nols_test_normality(Model1)\nols_plot_resid_qq(Model1)\n\n# Check equal variance\nols_test_breusch_pagan(Model1)\n\n#Check for influential outliers\nols_plot_resid_lev(Model1)\n\n# Check for multicollinearity\nols_vif_tol(Model1)\n\n\n\nMaking maps of residuals and training data\nHere are some professional maps I made of the output. I hope this is useful in your future careers!\n\n# You can also look at the residuals and make a map if you like\n# No newdata because you're predicting the training data values\nTrainingData$Model1Prediction <-  predict(Model1)\nTrainingData$Model1Residuals  <-  residuals(Model1)\n\n\n# Make it spatial\nTrainingData.sf  <- st_as_sf(TrainingData,crs=MyMapProjection, coords=c(\"X\",\"Y\"))\n\n# And map. Rather than plotting all at once, I save these 3 maps \n# remember to change the column name (dots.col) if you change your response!\n# google brewer.pal for more colors\n\nMap_y <- qtm(TrainingData.sf,\n    dots.col=\"Temp_F\", \n    dots.palette = rev(brewer.pal(7, \"Spectral\")),  \n    dots.size=.3,alpha=.5) +\n    tm_shape(st_geometry(TrainingBorder))+tm_borders() # add border\n\nMap_yhat <- qtm(TrainingData.sf,\n    dots.col=\"Model1Prediction\", \n    dots.palette = rev(brewer.pal(7, \"Spectral\")), \n    dots.size=.3,alpha=.5) +\n    tm_shape(st_geometry(TrainingBorder))+tm_borders() # add border\n\n\nMap_Residuals <- qtm(TrainingData.sf,\n    dots.col=\"Model1Residuals\",\n    dots.palette = brewer.pal(5, \"BrBG\"), # google brewer.pal for more\n    midpoint=NA,dots.size=.3,alpha=.5,\n    title=\"Residuals\") +\n    tm_shape(st_geometry(TrainingBorder))+tm_borders() # add border\n\n# Then arrange them together\n# You can choose between static maps \ntmap_mode(\"plot\")\ntmap_arrange(Map_y,Map_yhat,Map_Residuals)\n\n\n\n# OR dynamic ones. Don't use both!\ntmap_mode(\"view\")\ntmap_arrange(Map_y,Map_yhat,Map_Residuals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# tidy up\nrm(Map_y);rm(Map_yhat);rm(Map_Residuals)\n\n\n\nComparing models\nLet’s say you created Model1 and Model2 above\n\n# To compare models, or use the model summaries.\nAIC(Model1,Model2)\n\n\n# To look at many models, first create a model with all the data\nFullModel <- lm(Temp_F ~ .,data=TrainingData)\nols_step_best_subset(FullModel)\n\n\n\nMaking predictions (UPDATED/EASIER)\nWe now need to predict the answers to find where to put your temperature sensor. First, add a prediction column to your output.\nNote this also works for Predict.df - I made them identical at the top\n\nPredictionData$Prediction <- predict(Model1,newdata=PredictionData)\n\nAnd map\n\n#tm_shape loads a new layer\n#tm_raster and tm_lines plots it depending on what type of data you want.\n\ntm_shape(PredictionData$Prediction) + \n   tm_raster(alpha=0.7, style=\"cont\",\n             palette=rev(brewer.pal(7,\"RdYlBu\")),\n             title=\"Temperature (F)\") +  \n   tm_shape(TrainingBorder) + \n      tm_borders()          +\n   tm_shape(predictBorder)  + \n      tm_borders(col=\"red\") +  \n   tm_layout(\"Prediction for Model 1\",inner.margins=c(0,0,.1,0), title.size=.8)\n\n\n\n\n\nYou can also make a map where you identify the coldest locations like this\n\n# Find the cut-off value for the lowest 5% of points\ncutoff_5Percent <- quantile(as.points(PredictionData$Prediction),\n                              probs = c(0.01), na.rm = TRUE)\n\n# Create some outputs, either a layer\nColdestLayer_5per <- PredictionData$Prediction \nColdestLayer_5per[ColdestLayer_5per > cutoff_5Percent] <- NA\n\nOr select the coldest pixels. This arranges them in order, and then you can select at will.\n\n# or the actual points\nlowestpixels <- as.data.frame(PredictionData$Prediction,xy=TRUE)\nnames(lowestpixels) <- c(\"X\",\"Y\",\"Prediction\")\nlowestpixels <- lowestpixels[with(lowestpixels,order(Prediction)),]\n\nlowest100pixels <- lowestpixels[1:100,]\n\nThere are a few ways you could visualise this\n\n# And map\ntm_shape(ColdestLayer_5per$Prediction) + \n   tm_raster(alpha=0.7, style=\"cont\",\n             palette=rev(brewer.pal(7,\"Blues\")),\n             title=\"Temperature (F)\") +  \n   tm_shape(TrainingBorder) + \n      tm_borders()          +\n   tm_shape(predictBorder)  + \n      tm_borders(col=\"black\") +  \n   tm_layout(\"Coldest 1% of pixels in Model 1\",\n             inner.margins=c(0,0,.1,0), title.size=.8)\n\n\n\n\n\nOr add symbols\n\ntm_shape(PredictionData$Prediction) + \n   tm_raster(alpha=0.7, style=\"cont\",\n             palette=rev(brewer.pal(7,\"RdYlBu\")),\n             title=\"Temperature (F)\") +  \n   tm_shape(TrainingBorder) + \n      tm_borders()          +\n   tm_shape(predictBorder)  + \n      tm_borders(col=\"black\") +  \n   tm_layout(\"Prediction for Model 1\",inner.margins=c(0,0,.1,0), title.size=.8)+\n   tm_shape(st_as_sf(lowest100pixels,coords=c(\"X\",\"Y\"),crs=MyMapProjection))+\n     tm_dots(col = \"red\",alpha=.7)\n\n\n\n\n\n\nOr both!\n\n# And map\ntm_shape(ColdestLayer_5per$Prediction) + \n   tm_raster(alpha=0.7, style=\"cont\",\n             palette=rev(brewer.pal(7,\"Blues\")),\n             title=\"Temperature (F)\") +  \n   tm_shape(TrainingBorder) + \n      tm_borders()          +\n   tm_shape(predictBorder)  + \n      tm_borders(col=\"black\") +  \n   tm_layout(\"Coldest 20 pixels in Model 1\",\n             inner.margins=c(0,0,.1,0), title.size=.8)+\n   tm_shape(st_as_sf(lowestpixels[1:20,],coords=c(\"X\",\"Y\"),crs=MyMapProjection))+\n     tm_dots(col = \"red\",alpha=.7)\n\n\n\n\n\n# or to zoom in, switch the order\n   tm_shape(st_as_sf(lowestpixels[1:100,],coords=c(\"X\",\"Y\"),crs=MyMapProjection))+\n     tm_dots(col = \"red\",alpha=.7)+\ntm_shape(ColdestLayer_5per$Prediction) + \n   tm_raster(alpha=0.7, style=\"cont\",\n             palette=rev(brewer.pal(7,\"Blues\")),\n             title=\"Temperature (F)\") +  \n   tm_shape(TrainingBorder) + \n      tm_borders()          +\n   tm_shape(predictBorder)  + \n      tm_borders(col=\"black\") +  \n   tm_layout(\"Coldest 100 pixels in Model 1\",\n             inner.margins=c(0,0,.1,0), title.size=.8)"
  },
  {
    "objectID": "in_S462_Project03InitialEDA.html",
    "href": "in_S462_Project03InitialEDA.html",
    "title": "3. Initial EDA (this week)",
    "section": "",
    "text": "We have data! Now is the time to explore it and to make some initial models."
  },
  {
    "objectID": "in_S462_Project03InitialEDA.html#set-up",
    "href": "in_S462_Project03InitialEDA.html#set-up",
    "title": "3. Initial EDA (this week)",
    "section": "Set-up",
    "text": "Set-up\nYou can choose whether to use your RStudio cloud account or your own computers for this task (For RStudioCloud it seems that only one person can use a project effectively, so you’re welcome to use your shared space, but set up individual projects).\nYou can always copy/paste your final results together.\n\nEVERYONE (individually)\n\nSet up a project and get the data\n\nUse Tutorial 2 to create a new project (or use a sensible existing project). If you are using the shared cloud space, work in individual projects. Keep following the tutorial to create a new .RmD file.\nAt the very top, either create or edit a code chunk that looks like this. This will stop the annoying library packages loading when you knit. Here’s the text to copy/paste:\n\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message=FALSE,warning=FALSE)\n\n\n\n\n\n\n\n\nBelow that, create a new code chunk to load these libraries. You might need to install some using Tutorial 2.2.\n\n\nlibrary(readxl)  # read in data\nlibrary(sf)      # spatial\nlibrary(sp)      # spatial\nlibrary(raster)  # spatial\nlibrary(terra)   # spatial\nlibrary(tidyverse) # ALL\nlibrary(tmap)    # mapping\n\n\nGo to visual mode. Create a new header 1 called Exploratory Analysis\n\nClick this link to download the data: CLICK HERE. and put it in your project file. Use these commands to read it into R. The first one will create a data.frame (table) of your data. The second will create a “spatial version” that is easy to map. Press knit and check all is well.\n\n\nDataIn <- read_excel(\"STAT462_TrainingData.xlsx\")\nDataIn <- na.omit(DataIn)\nDataIn.sf <- st_as_sf(DataIn,coords=c( \"X\",\"Y\"),crs=\"EPSG:32617\")\n\n\nnames(DataIn)\n\n [1] \"Serial\"                  \"X\"                      \n [3] \"Y\"                       \"Elevation_1m\"           \n [5] \"Slope_1m\"                \"Roughness_1m\"           \n [7] \"Aspect_1m\"               \"LandCover_Code\"         \n [9] \"NCLD_Percent_Tree_Cover\" \"NCLD_Percent_Concrete\"  \n[11] \"Date\"                    \"Hour\"                   \n[13] \"Temp_F\"                  \"Light_Lux\"              \n[15] \"Notes\"                  \n\n\n\nOpen the data and take a look at it. (click on its name or put View(DataIn) IN THE CONSOLE\n\nYou should see the following columns\n\nSerial: the serial number of the item\nX and Y. The location of the item in X and Y metre coordinates (Long/Lat coordinates are poor over small areas, so I’m using the WGS84 17N / Pennsylvania North map projection (https://epsg.io/32617))\nElevation_1m : The elevation of the sensor to the closest metre from the USGS 1 meter Digital Elevation Model\nSlope_1m : The slope of the location where the sensor was placed, from the same USGS DEM\nAspect_1m : The aspect of the location where the sensor was placed., from the same USGS DEM\nRoughness_1m : The roughness of the location where the sensor was placed, from the same USGS DEM\nLandCover_Code: The NCLD landcover code for that location\nNCLD_Percent_Tree_Cover: The percent tree cover for that location\nNCLD_Percent_Concrete : The percent concrete at that location\nDate: Date of the measurement\nHour: Hour of the measurement\nTemp_F: The temperature measurement\nLight_Lux: The Light measurement\nNotes: Placement Notes\n\n\n\n\n\nGROUP challenges\nNow, there are several challenges that you can split as a group depending on your strengths.\n\nDescribing the data and the meta data. This means\n\nExplaining the unit of analysis, the population and the variable\nResearching and writing up why they have been “transformed” into UTM (hint: CLICK HERE)\nResearching and writing about each of the predictor variables (e.g. a few sentences about what it is etc, google and the links above should help, or ask me questions on Teams)\n\n\nMaking summary statistics and plots of the DataIn table. For example\n\nHow many sensors are there (hint, table command)\nAny missing data?\nFiltering the data to just one sensor, or one time of day (hint, this will really help: https://crd150.github.io/lab2.html#Data_Wrangling) and making a plot of the temperature over time, or say a histogram of the temps on a single day.\nFiltering the data in other ways and making exploratory plots and histograms.\n\n\nQuality controlling the data. For example,\n\nCan you trust all the readings at all times of day? Can you see examples of where there are issues.\nWhat about over all dates? Anything weird happening?\nIf you find things, decide whether you should keep or remove them AND WRITE DOWN WHAT YOU DID/CHANGED.\n\n\nUsing DataIn.sf Make some initial maps, especially of static variables that don’t change over time.\nYou could use QTM from the previous lab, for example\n\n\ntmap_mode(\"view\")\n\nqtm(DataIn.sf,\n            dots.col=\"NCLD_Percent_Tree_Cover\")+\n           tm_layout(legend.outside = TRUE)\n\n\n\n\n\n\n\nOr better still.. follow these instructions (https://psu-spatial.github.io/Geog364-2021/364Data_TutorialWranglePoint.html) or https://r-tmap.github.io/tmap-book/nutshell.html to make prettier ones.\n\nExplore the data.\n\nFinally, choose one different predictor variable each - and make a scatterplot to look at the impact on temperatures and a basic linear model.\n\nCritique your model so far, especially seeing if it visually fits the LINE assumptions.\nHow can we do better? Feel free to try other options and Lab 3 will help.."
  },
  {
    "objectID": "in_S462_Project03InitialEDA.html#combine-your-work-into-an-exploratory-data-analysis-part-of-your-report.",
    "href": "in_S462_Project03InitialEDA.html#combine-your-work-into-an-exploratory-data-analysis-part-of-your-report.",
    "title": "3. Initial EDA (this week)",
    "section": "Combine your work into an exploratory data analysis part of your report.",
    "text": "Combine your work into an exploratory data analysis part of your report."
  }
]