[
  {
    "objectID": "in_S462_Tutorial7Distributions.html",
    "href": "in_S462_Tutorial7Distributions.html",
    "title": "T7: Normal, T Distributions and tests",
    "section": "",
    "text": "We have talked about several distributions and tests so far in the lab. To see the help files for most of them, see ?Distributions\nRemember as we discussed in lectures, we normally state that a variable is ~N(mean, VARIANCE). But in these commands you need the standard deviation instead. (you can google how to get the sd from the variance if you have forgotten)\nTo see the help file for all these:\n\n?Normal\n\nTo generate a random sample from a normal distribution:\n\nsample.normal <- rnorm(n=100,mean=4,sd=2)\n\nTo calculate a z score from your sample/population, you can use R as a calculator.\nTo calculate the probability of greater/lesser than a value in a given normal distribution (e.g. you can use this as an interactive table)\n\n# probability of less than 1.7 in a normal distribution of N(4,2^2)\npnorm(1.7,mean=4,sd=2,lower.tail = TRUE)\n\n[1] 0.1250719\n\n# probability of greater than 1.8 in a normal distribution of N(4,2^2)\n1 - pnorm(1,mean=4,sd=2,lower.tail = TRUE)\n\n[1] 0.9331928\n\n# or\npnorm(1,mean=4,sd=2,lower.tail = FALSE)\n\n[1] 0.9331928\n\n\nTo calculate the value for a given probability\n\n# what value is less than 60% of the data?\nqnorm(0.6,mean=4,sd=2,lower.tail = TRUE)\n\n[1] 4.506694\n\n# what value is greater than 80% of the data?\nqnorm(0.8,mean=4,sd=2,lower.tail = FALSE)\n\n[1] 2.316758\n\n\n\n\nTo test for normality:\nFirst, have a look at the histogram! Here is the code for the Shapiro-Wilk test.\n\nshapiro.test(HousesNY$Price)\n\n\n    Shapiro-Wilk normality test\n\ndata:  HousesNY$Price\nW = 0.96341, p-value = 0.1038\n\n\n\n\n\nYou can also make a QQ-Norm plot\nWe discussed the basic qqnorm command last week: qqplot(variable). For example `qqplot(malepirates$age)`` makes a qq-norm plot of the age column in the data.frame I created earlier on male pirates. There is a nicer version inside the ggpubr package.\n\nlibrary(ggpubr)\nggqqplot(HousesNY$Price,col=\"blue\")\n\nYOU CAN INTERPRET IT HERE: https://www.learnbyexample.org/r-quantile-quantile-qq-plot-base-graph/"
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html",
    "href": "in_S462_Tutorial2BeforeEachLab.html",
    "title": "T2. Before Each Lab",
    "section": "",
    "text": "In this class, we will be using a new R-Project for each lab. An R-project is a folder that will store everything to do with each lab in one place on your computer. On the website, each lab will be its own project.\nThis is incredibly useful - it means that if you switch from R-Cloud, to the lab computers, to your laptop, all you have to do is to move the folder and everything will just work. Equally, its easy to compare labs.\n\nCLICK HERE to learn how to create/return to and use projects on R studio cloud.\nCLICK HERE to learn how to create/return to and use projects on R-Desktop.\n\nLearn more here."
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#what-is-markdown",
    "href": "in_S462_Tutorial2BeforeEachLab.html#what-is-markdown",
    "title": "T2. Before Each Lab",
    "section": "What is Markdown?",
    "text": "What is Markdown?\nYou might wonder at this point about how to save your work.\nTyping into console is like having a phone call with your computer; you’re talking but you’re not keeping records of what you say. To see previous commands, you can click the history tab (Environment quadrant) or press the up/down arrows on your keyboard, but when you close R, all record of these commands will be lost. We need instead is a way to save the commands for future use - we can do this using scripts.\nThere are several types of document, or script that you can create and save in R-Studio. There are about 20 options in the file menu.\nIn this course we are going to focus on the R-Markdown format and you are going to submit your labs as websites/html files along with your code.\nImagine a normal Microsoft Word document, but halfway through you can press a button and a mini R console appears. You type your code inside the mini console, it runs and puts the plots/output just below - then you leave the console and continue writing about the results. Essentially you never have to take another screenshot of results and move it to your output… Rmd files are also flexible. You can turn them into reports, websites, blogs, presentations or applications with a few short commands.\nRead more here: https://rmarkdown.rstudio.com or watch this short video"
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#creating-a-markdown-document",
    "href": "in_S462_Tutorial2BeforeEachLab.html#creating-a-markdown-document",
    "title": "T2. Before Each Lab",
    "section": "Creating a markdown document",
    "text": "Creating a markdown document\nFirst, (if you did not already do this) - go to the Packages menu in one of the quadrants, click “install” and install rmdformats. It will give you nice templates without having to learn YAML code)\nGo to the File menu on the top left, then click New File - R-Markdown. If this is your first time ever, it might ask to download some packages to be able to do this. Say yes.\nEventually a window will open up:\n\n\n\n\n\n\n\n\n\nClick “From Template” and select a template of your choice. Click here to see what different templates look like:\nhttps://juba.github.io/rmdformats/\nIt will ask you to name your file. Give it a relevant name including your email ID, like Lab-2_hlg5155. A new file should appear on your screen.\nEssentially, we have some space for text, some space for code, and a space at the top of the file where we can add information about themes/styles etc. Each grey code area is called a “code chunk”. To run the code inside it, click the little green arrow on the top right.\nDepending on the template, your file might contain some friendly text to explain what is going on, which I have annotated here. Read through it, then you are welcome to delete it from line 11 downwards (keep the knitr code chunk)"
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#three-important-buttons---read-this",
    "href": "in_S462_Tutorial2BeforeEachLab.html#three-important-buttons---read-this",
    "title": "T2. Before Each Lab",
    "section": "THREE IMPORTANT BUTTONS - READ THIS",
    "text": "THREE IMPORTANT BUTTONS - READ THIS\n\n\n\n\n\n\n\n\n\n\nVisual mode\nIt is MUCH easier to edit markdown documents in the new visual mode. Essentially instead of having to remember text short cuts like * for bold, you can edit the text part as though you were using a word processor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRunning Code\n\n\n\n\n\n\n\n\n\nOn the top right there are a suite of buttons for adding a new code chunk, running code etc.\n\n\nKnitting\n\n\n\n\n\n\n\n\n\nThe file on your screen isn’t the finished article. To see how it will look as a final version, we need to “knit” it. Go to the top of the .Rmd file, find the knit button. Press it (you might have to first save your script if you haven’t already, then press it again)\nYou should see that the Markdown tab “builds” your document and you get an output as a website. The html should also be saved into your project folder. For example, from my other class, here is a file with markdown and knitted output.\n\n\n\n\n\n\n\n\n\nIf your file looks blank, have you typed anything yet in the script? ;)"
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#what-are-packages",
    "href": "in_S462_Tutorial2BeforeEachLab.html#what-are-packages",
    "title": "T2. Before Each Lab",
    "section": "What are packages?",
    "text": "What are packages?\nAs described earlier, we program in R by typing a series of commands. R is open source and anyone can create a new command. Just as people keep creating apps for phones, over the last 20 years,tens of millions of new custom commands have been created.\nCommands tend to be grouped together into collections called Packages or Libraries (two names for the same thing). For example, one package contains the complete works of Shakespeare; another allows interactive website design; another allows advanced Bayesian statistics. There is a package for literally everything and there are now over 20,000 packages available. You can see a selection here: https://cran.r-project.org/web/packages/available_packages_by_name.html\nJust as you don’t have every app in the world on your phone, this is far too much to store on your computer, so we choose the ones we need from a free online “app/package store”. You can download the ones you want, ready to load later.\nSo to access the commands in a package we need these two steps:\n\nONCE ONLY: Download the package from the internet, in the way you download an app from the app store\nEVERY TIME: Load the packages you want, like clicking an app icon to open it.\n\nA close analogy is your phone: There are millions of apps available from banking, to 50 different calendar apps. You don’t have every app in the world installed on your phone - and you don’t have every app you do download running at the same time.  Instead you download the apps that you think you will need (occasionally downloading a new one on the fly) - and when you need to use an app, you click on it to open."
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#downloading-a-new-package",
    "href": "in_S462_Tutorial2BeforeEachLab.html#downloading-a-new-package",
    "title": "T2. Before Each Lab",
    "section": "Downloading a new package",
    "text": "Downloading a new package\nNote, if you run this command multiple times, or the packages is already loaded, R-Studio might want to restart and sometimes gets confused. If it keeps asking, close R-studio, reopen and try again. If it really doesn’t want to work, open the R program itself and run in the console there.\n\nManually click\nThis is like going to the app store to get a new app. Just like you only go to the app store once, this is a one-off for each package. NOTE! For R studio cloud online, you might have to do this for each project.\n\nLook for the quadrant with the packages tab in it.\n\nYou will see a list of packages/apps that have already been installed.\nClick the INSTALL button in the Packages tab menu (on the left)\nStart typing the package name and it will show up (check the include dependencies box). Install the package.\n\n\n\n\nLittle yellow banner\n\nR will sometime tell you that you are missing a package (sometimes a little yellow ribbon), click yes to install!\n\n*Note 2, Sometimes R will ask you if you want to install binaries or other things. IT WILL ASK THIS IN THE CONSOLE. It expects you to type yes or no, and to press enter to continue. Try yes, if it doesn’t work (esp xfun), try no.\n\n\nUsing the console\nYou can also use a command to install a new package:\n\ninstall.packages(\"bardr\")\n\nDO NOT INCLUDE THIS IN YOUR FINAL SCRIPT. The command means “go to the app store” and download a package. You don’t want to do this when pressing knit."
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#loading-a-package-important",
    "href": "in_S462_Tutorial2BeforeEachLab.html#loading-a-package-important",
    "title": "T2. Before Each Lab",
    "section": "Loading a package (IMPORTANT)",
    "text": "Loading a package (IMPORTANT)\nJust as going to the app store doesn’t open instagram, simply downloading a package from the app-store doesn’t make the commands immediately available.\nFor that you need to load it (like clicking on an app). This can be done with the library() command.\nIn the console type this to install the full works of Shakespeare in the bardr package. (https://www.rdocumentation.org/packages/bardr/versions/0.0.9). You might need to install it first.\n\nlibrary(bardr)\n\nI suggest keeping all your library() commands in a code chunk near the top of the file and running that.. e.g.\n\n\n\n\n\n\n\n\n\nI will tell you which packages you need for each lab, but if R tells you it wants a package, then install it AND load it\nIf you have managed to load a package successfully, often nothing happens - this is great! It means it loaded the package without errors. Otherwise, I suggest running this command TWICE! This is because loading packages will print “friendly messages” or “welcome text” the first time you load them.\nFor example, this is what shows up when you install the tidyverse package. The welcome text is indicating the sub-packages that tidyverse downloaded and also that some commands now have a different meaning.\n\n\n\n\n\nTidyverse install messages\n\n\n\n\nTo find out if what you are seeing is a friendly message or an error, run the command again. If you run it a second time and there is no error then nothing should happen."
  },
  {
    "objectID": "in_S462_Tutorial2BeforeEachLab.html#use-a-single-command-from-a-package",
    "href": "in_S462_Tutorial2BeforeEachLab.html#use-a-single-command-from-a-package",
    "title": "T2. Before Each Lab",
    "section": "Use a single command from a package",
    "text": "Use a single command from a package\nSometimes multiple packages name a command the same thing and you want to specify which package you want to use. You can do this using the :: symbol\nFor example, this command forces the computer to use the ‘dplyr package’ version of filter.\n\ndplyr::filter(mydata)"
  },
  {
    "objectID": "in_S462_Project1MakingGroups.html",
    "href": "in_S462_Project1MakingGroups.html",
    "title": "1. Making teams",
    "section": "",
    "text": "DO NOT TAKE THIS SERIOUSLY - EVERYONE CAN FIT INTO ALL OF THESE GROUPS.\n\n\n\n\n\nFigure from https://xkcd.com/52/\n\n\n\n\nNone of this is part of our course. You do not have to reproduce it, learn it or do this in R. But it gets to the heart of regression… you are just imagining models and seeing how the data best fits.\nI made this quiz in 10mins flat and the “model” was pretty hard to read. With that in mind, remember that those big sophisticated models that put us in groups on social media might be wrong too.. They’re just guesses based on the imperfect information we feed them.\nI also wanted you to see how cool these interactive markdown documents are."
  },
  {
    "objectID": "in_S462_Project1MakingGroups.html#using-unsupervised-learning-for-personalities..",
    "href": "in_S462_Project1MakingGroups.html#using-unsupervised-learning-for-personalities..",
    "title": "1. Making teams",
    "section": "Using unsupervised learning for personalities..",
    "text": "Using unsupervised learning for personalities..\nThere is definitely no “right” answer when it comes to human personality. We change from day to day and people make millions from the ability to get humans to work together. I certainly know nothing about you all, but I do know that groups work best when there are people able to fill certain roles.\nIn the past when I have taught group projects, people have either split via friendship, alphabetical order or the people sitting around them, which tends to leave many groups unbalanced. I was interested to see if a basic personality quiz and unsupervised machine learning could do better.\nThe other reason I wanted to see this is that my model is a very, very simple version of what the social internet does. People often hear the myth that your phone “hears” what people say and shows you adverts. The likely reality is maybe even more disturbing.. that there are models so sophisticated that they can predict and market what you want before you realise you want it.."
  },
  {
    "objectID": "in_S462_Project1MakingGroups.html#step-1.-coding-the-quiz",
    "href": "in_S462_Project1MakingGroups.html#step-1.-coding-the-quiz",
    "title": "1. Making teams",
    "section": "Step 1. Coding the quiz",
    "text": "Step 1. Coding the quiz\nI could have probably put your raw data into a model, but to make life easier on myself, I decided to assign a tag to each question with a corresponding “score”. Some questions didn’t really fit in the end, so I tagged those “ignore” and I tried a load of combinations before ending up with the exact roles above.\nYou can see my codes here, attached to each question number & option.\n\n# From the readxl package\nCodes <- read_excel(\"Project1_PersonalityKey_Final.xlsx\")\n\n# This will print it nicely\nCodes\n\n# A tibble: 71 × 9\n   Question       Code           AllGr…¹ Score Roles RoleS…² Style Style…³ Text \n   <chr>          <chr>          <chr>   <dbl> <chr>   <dbl> <chr>   <dbl> <chr>\n 1 1_Location     Adventure      Ignore      0 Igno…       0 Igno…       0 Im e…\n 2 1_Location     Arboretum      Ignore      0 Igno…       0 Igno…       0 I ca…\n 3 1_Location     CampusFocus    Ignore      0 Igno…       0 Igno…       0 I do…\n 4 1_Location     CarAccess      Ignore      0 Igno…       0 Igno…       0 I ha…\n 5 1_Location     Hiking         Ignore      0 Igno…       0 Igno…       0 Love…\n 6 1_Location     SkiAccess      Ignore      0 Igno…       0 Igno…       0 I ca…\n 7 1_Location     StateCollegeK… Ignore      0 Igno…       0 Igno…       0 I kn…\n 8 2_R_Competency Expert         Role_M…     2 Role…       2 Igno…       0 Love…\n 9 2_R_Competency Intermediate   Role_M…     1 Role…       1 Igno…       0 Ive …\n10 2_R_Competency StartingOut    Role_M…    -1 Role…      -2 Igno…       0 Ive …\n# … with 61 more rows, and abbreviated variable names ¹​AllGroups, ²​RoleScore,\n#   ³​StyleScore"
  },
  {
    "objectID": "in_S462_Project1MakingGroups.html#step-2.-quality-control",
    "href": "in_S462_Project1MakingGroups.html#step-2.-quality-control",
    "title": "1. Making teams",
    "section": "Step 2. Quality Control",
    "text": "Step 2. Quality Control\nBecause I didn’t spend time setting up Canvas in advance, I then needed to find a way to match each of your answers to their equivalent score. This took a few steps:\n\nI saved your Canvas answers as an excel spreadsheet.\nR hates special characters like ” ! , ’ etc, so I selected the entire sheet then used find/replace to remove anything that I could think of. I did the same to the questions in the coding sheet so they would match.\nI then read the data into R. One column for each question. The object of analysis is a student.\n\n\nQuizData <- read_excel(\"Project 1_ CanvasAns_ReadyForR.xlsx\")\n\n# Showing the column names to keep the data more private and removing the second langauge data (column 14)\nQuizData <- QuizData[-14]\n\nNow I wanted to automatically change the canvas answers to the codes I made and I wanted to be general enough that if I changed a code, it could be easy to just re-run. This is messy coding! There are many more efficient ways to do it, but… it gets the job done. The output of this code is three tables where each person’s answers/options are coded using my tags\n\n# I'm now going to make three output datasets, one for just roles, \n# one for just group style and one for both\nRoles <- QuizData\nStyles <- QuizData\n\n\n## Read in coding dataset\nCodingKey <- read_excel(\"Project1_PersonalityKey_Final.xlsx\")\nCodingKey$UniqueCode <- paste(CodingKey$Question, CodingKey$Code,sep=\"_\")\n\n## Work out the unique questions. I made sure these match the column name\nUnique_Qu <- unique(CodingKey$Question)\n\n# For every question, find the location in both datasets and replace\n# I'm certain there is a one line answer to this involving the merge command\n# but this worked easiest for my brain\n\n# For each question\nfor(n in 1:length(Unique_Qu)){\n  # Find the column location for that question\n  col_location <- which(names(QuizData) == Unique_Qu[n])\n  \n  # And get the unique question options from the Coding key\n  QuestionKey <- CodingKey[CodingKey$Question ==  Unique_Qu[n] ,]\n  \n  # For every option\n  for(option in 1:nrow(QuestionKey)){\n    # For every person, because stringr was annoying\n    for(row in 1:nrow(QuizData)){\n      # Replace the question text with the tags\n      Roles[row,col_location] <- str_replace_all(Roles[row,col_location],\n                                                  QuestionKey$Text[option],\n                                                  QuestionKey$Roles[option])\n      \n      Styles[row,col_location] <- str_replace_all(Styles[row,col_location],\n                                                  QuestionKey$Text[option],\n                                                  QuestionKey$Style[option])\n      \n    }\n  }\n}  \n\n#adjust the column names, R doesnt like them starting with a number and I am too lazy to go back\nnames(Roles) <- paste(\"Q\",names(Roles),sep=\"\")\nnames(Styles) <- paste(\"Q\",names(Styles),sep=\"\")\n\nOK, that’s great - now each of your options has the correct code.. BUT I also need to assign the scores! For example if you said you hated art, I don’t want you to rank highly as an artist. This code does that for the roles\n\n\n# Get each person's identifier. CHANGE THIS HLG\nRoleCodes <- Roles[,1:4]\n\n# Make new blank columns for each CODE rather than question e.g. artist role\nfor(col in 1:length(unique(CodingKey$Roles))){\n  RoleCodes[,4+col] <- NA\n  names(RoleCodes)[4+col] <- unique(CodingKey$Roles)[col]\n}\ncols <- 5:ncol(Roles)\nRoles$AllAns <- apply( Roles[ , cols ] , 1 , paste , collapse = \",\" )\n\n# For each person and each Meta Code\nfor(p in 1:nrow(RoleCodes)){\n  #This splits all your answer tags into a frequency table\n  tmp <- data.frame(table(str_split(Roles$AllAns[p],\",\")[[1]]))\n  for(n in 1:nrow(tmp)){\n    newcol <- which(names(RoleCodes) %in% tmp[n,1])\n    RoleCodes[p,newcol] <- tmp[n,2]\n  }\n  \n}\n\nand the same for the working style.. I did say it was messy code!\n\n\n# Get each person's identifier. CHANGE THIS HLG\nStyleCodes <- Styles[,1:4]\n\n# Make new blank columns for each CODE rather than question e.g. artist Style\nfor(col in 1:length(unique(CodingKey$Style))){\n  StyleCodes[,4+col] <- NA\n  names(StyleCodes)[4+col] <- unique(CodingKey$Style)[col]\n}\ncols <- 5:ncol(Styles)\nStyles$AllAns <- apply( Styles[ , cols ] , 1 , paste , collapse = \",\" )\n\n# For each person and each Meta Code\nfor(p in 1:nrow(StyleCodes)){\n  tmp <- data.frame(table(str_split(Styles$AllAns[p],\",\")[[1]]))\n  for(n in 1:nrow(tmp)){\n    newcol <- which(names(StyleCodes) %in% tmp[n,1])\n    StyleCodes[p,newcol] <- tmp[n,2]\n  }\n  \n}\n\n# manually stick them together into one\nCodedData <- cbind(RoleCodes[,c(1:4,6:9)],StyleCodes[,6:7])\n\n# and replace any NA's with 0 (e.g. people didn't choose enough to give an opinion)\nCodedData[is.na(CodedData)==TRUE] <- 0\n\nOK! Here are the results. You all shared your introduction posts with each other, but to preserve privacy I am displaying them as your email ID. For later plots, I will use anonymous tags.\nREMEMBER, THIS IS JUST BASED ON MY BIASED INTERPRETATION OF QUICK QUESTIONS AND TAGGING. IT’S NOT “TRUTH”. For example, maybe there is some cultural or implicit bias in my questions or the way I phrased them so that some students interpreted them differently..\n\nCodedData[,c(2,5:10)]\n\n   QEMailID Role_Modeller Role_Artisan Role_Coordinator Role_Designer\n1   pjd5319             3            3                3             2\n2   zvl5464             3            3                3             2\n3   ovm5126             1            4                5             3\n4   djd6132             2            4                1             3\n5   hks5418             1            3                4             2\n6   dfc5439             2            3                3             1\n7   kml6610             2            4                4             2\n8   kzp5527             3            3                5             2\n9   bmd5735             2            3                4             2\n10  nbs5387             3            2                4             3\n11  yqf5150             2            2                3             3\n12  eky5058             3            2                4             2\n13  rmc6084             2            3                2             2\n14  amg6850             2            4                2             3\n15  gkk5160             3            5                2             2\n16  cjt5577             3            2                4             2\n17  jvc6258             4            1                4             1\n18  mfb6052             3            2                4             2\n19  hml5431             3            3                3             3\n20  jmz5672             2            3                4             2\n21  jfh5948             3            2                3             2\n22  rxy5109             2            2                3             3\n23  sqe5219             2            5                4             1\n24  srm5966             2            3                1             4\n25  avs7076             2            2                4             1\n26  xzz5374             3            4                4             2\n27  gks5260             2            4                2             3\n28  jxt5575             2            4                1             3\n29  kpm5881             1            4                3             2\n30  leo5097             3            4                3             2\n31  mfc5873             3            2                3             2\n32  wxg5137             3            3                4             3\n33  esr5189             2            4                3             2\n34     yzl9             3            4                5             1\n35  gbs5322             3            2                2             4\n36  dgm5281             2            2                4             2\n37  erb5623             3            3                5             1\n38  jfp5556             2            3                3             2\n39    kzp35             3            1                3             1\n40  ajp6715             3            4                4             1\n41  nfl5163             2            3                1             3\n42  mjl6543             2            3                4             3\n   GroupStyle WorkingStyle\n1           3            3\n2           3            2\n3           3            2\n4           4            2\n5           2            4\n6           4            3\n7           3            2\n8           1            1\n9           2            4\n10          5            1\n11          1            2\n12          3            3\n13          4            2\n14          3            3\n15          4            1\n16          2            4\n17          3            2\n18          2            3\n19          3            3\n20          2            0\n21          3            2\n22          4            2\n23          3            3\n24          3            2\n25          4            3\n26          2            1\n27          3            6\n28          3            3\n29          3            4\n30          2            2\n31          2            3\n32          3            0\n33          3            3\n34          2            4\n35          3            2\n36          2            3\n37          2            3\n38          3            3\n39          2            5\n40          2            3\n41          2            3\n42          1            3"
  },
  {
    "objectID": "in_S462_Tutorial5LoadingData.html",
    "href": "in_S462_Tutorial5LoadingData.html",
    "title": "T5: Loading Data",
    "section": "",
    "text": "There are many datasets built into R, and even more that come with packages. To load them you simply use the data command. Typing data() will bring up a load of the possible datasets.\nFor example, this loads the iris dataset:\n\ndata(\"iris\")\n\n# From the dplyr package\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nIf you want to specify data from a specific package, we can also tell R that:\n\ndata(\"pirates\", package = \"yarrr\")\nmean(pirates$parrots)\n\n[1] 2.819\n\n\nAll the datasets in R have a help file by using the help menu or putting a ? in front of its name. DO THIS IN THE CONSOLE NOT A CODE CHUNK.\n\n?pirates\n\n\n\n\n\nR can easily read in Microsoft Excel spreadsheets using the readxl package:\n\nMake sure the readxl package is loaded.E.g. is library(readxl) in your library code chunk?Have you run the code chunk?\nPlace your excel file in your project folder.E.g. here I placed Data_frostday.xlsx into my project folder. MAKE SURE YOU OPEN R-STUDIO USING YOUR LAB PROJECT!! If you are not sure what I mean see Projects: How do I know if I am running one? and returning to your project\nMake a new code chunk and add the read_excel() command e.g.\n\nfrost <- read_excel(\"Data_frostday.xlsx\")\n\nHere the command is read_excel(), you are applying this to “frostdays.xlsx” (e.g. reading in an excel file with that name), then assigning the result to a variable called frost. Because you are using your project, R knows to look inside your project folder to find the file.\n\nIf this works, there should be no errors and nothing prints on the screen when you run the code chunk.\nWhen I ran it, in the environment tab, frost appeared with a description as a table with 76 rows (observations/obs), and 7 columns (variables). In R, this type of table/spreadsheet is called a data.frame.\n\n# Read in the frost.xlsx file in my project folder and assign it to a variable called frost\nlibrary(readxl)\nfrost    <- read_excel(\"Data_frostdata.xlsx\")\nnames(frost)\n\n[1] \"Station\"             \"State\"               \"Type_Fake\"          \n[4] \"Avg_DOY_SpringFrost\" \"Latitude\"            \"Longitude\"          \n[7] \"Elevation\"           \"Dist_to_Coast\"      \n\n\nOr you can put the full file path in the read_excel command\n\n# Read in the frost.xlsx file in my project folder and assign it to a variable called frost\nlibrary(readxl)\nfrost    <- read_excel(\"/Users/hlg5155/Documents/GitHub/Teaching/Stat462-2023/Data_frostdata.xlsx\")\nnames(frost)\n\n[1] \"Station\"             \"State\"               \"Type_Fake\"          \n[4] \"Avg_DOY_SpringFrost\" \"Latitude\"            \"Longitude\"          \n[7] \"Elevation\"           \"Dist_to_Coast\"      \n\n\n\n\n\nIt says it can’t find the file: - Are you running the right project? e.g. does it say Lab 3 at the top of the screen? - Did you put the file into your Lab folder? - Did you spell it right and include the full .xslx extension? - Did you use quote marks?\nIt says read_excel doesn’t exist - Did you install the readxl package? - Did you load the readxl package? Go click the code chunk with the library command again! - Did you spell the command right? (case sensitive) - Did you use () afterwards so R understands that it’s a command?\n\nUsing the wizard: Sometimes you just can’t get it working. In those cases, try the import wizard:\n\nGo to the file menu at the very top of the screen. Click import dataset, then From Excel. Use the wizard to find your file and get it looking correct. It will show you the code you need in the code preview.\nBecause we want to include this file in the markdown, rather than pressing OK, copy the code preview text and put it in your code chunk. DO NOT PUT THE VIEW LINE IN THERE, or every time you run it will open a new tab with the data.\n\n\n\n\n\n\n.csv files are comma separated text files, you can read them into microsoft excel. In R, you don’t need any special package to read in a csv file\n\nPlace the csv file into your project folder\nUse the read_csv() command to read it into R. Assign it to a variable or it will just print onto the screen\nRun the code chunk, then click on the variable name in the Environment quadrant to check that it read in correctly (especially make sure that column names have read in correctly)\n\nFor example, for to read in a csv file on ozone and summarise:\n\n# Read in the some data on ozone\nozone    <- read.csv(\"Data_Ozone.csv\")\n\n# Check the column names, or click on its name in the Environment quadrant\nsummary(ozone)\n\n    LOCATION     SITE_NAME          SHORT_NAME           LATITUDE    \n Min.   :2001   Length:451         Length:451         Min.   :32.35  \n 1st Qu.:2402   Class :character   Class :character   1st Qu.:34.15  \n Median :2844   Mode  :character   Mode  :character   Median :36.01  \n Mean   :2802                                         Mean   :36.14  \n 3rd Qu.:3134                                         3rd Qu.:37.94  \n Max.   :3759                                         Max.   :41.85  \n   LONGITUDE      OZONE_1000PPB    POPULATION_DENSITY\n Min.   :-124.2   Min.   : 3.457   Min.   :  0.0000  \n 1st Qu.:-121.5   1st Qu.:23.617   1st Qu.:  0.5499  \n Median :-120.0   Median :28.304   Median : 14.6029  \n Mean   :-119.7   Mean   :30.347   Mean   : 34.9754  \n 3rd Qu.:-118.0   3rd Qu.:35.254   3rd Qu.: 53.2731  \n Max.   :-114.6   Max.   :84.655   Max.   :406.6252  \n\n\n\n\n\nIt says it can’t find the file: - Are you running the right project? e.g. does it say Lab 2 at the top of the screen? - Did you put the file into your Lab 2 folder? - Did you spell it right and include the full .csv extension? - Did you use quote marks?\n\nUsing the wizard: Sometimes you just can’t get it working. In those cases, try the import wizard:\n\nGo to the file menu at the very top of the screen. Click import dataset, then From Excel. Use the wizard to find your file and get it looking correct. It will show you the code you need in the code preview.\nBecause we want to include this file in the markdown, rather than pressing OK, copy the code preview text and put it in your code chunk. DO NOT PUT THE VIEW LINE IN THERE, or every time you run it will open a new tab with the data.\n\n\n\n\n\nSame as above but you use the read.txt command. You get a lot of options here, from telling R if it has headers/column names to changing the ‘delimiter’. See the help file and http://www.sthda.com/english/wiki/reading-data-from-txt-csv-files-r-base-functions for more."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html",
    "href": "in_S462_Tutorial3RBasics.html",
    "title": "T3: Console-Basics and help",
    "section": "",
    "text": "First watch this 5 min video above for some pointers. We will also go through the video more slowly below:"
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#spacing-and-capital-letters",
    "href": "in_S462_Tutorial3RBasics.html#spacing-and-capital-letters",
    "title": "T3: Console-Basics and help",
    "section": "Spacing and Capital Letters",
    "text": "Spacing and Capital Letters\n\nSpacing mostly does not matter: 1+1 will generate the same answer as 1      +       1.\n\nException: you cannot have a space between a command name and its ( ) e.g sin (2) will fail`\n\nCapital letters DO matter. R is case sensitive.\nTo see previous commands, you can click the history tab (Environment quadrant) or press the up/down arrows on your keyboard, but when you close R, all record of these commands will be lost."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#Tut3B_Calc",
    "href": "in_S462_Tutorial3RBasics.html#Tut3B_Calc",
    "title": "T3: Console-Basics and help",
    "section": "R as a calculator",
    "text": "R as a calculator\nWhen using R as a calculator, the order of operations is the same as you would have learned back in school, so use brackets to force a different order. For example, in either the console or a script, try running these two commands\n\n3 + 5 * 2\n\nand\n\n(3 + 5) * 2\n\n\nWe can also take shortcuts with our numbers. For example 1:5 means take all the numbers 1 2 3 4 5 (e.g. increment the integers one - to - five). Try typing this command and make sure you understand the result.\n\n(1 + 2) * 5:3\n\n[1] 15 12  9\n\n\n\nWe can use this trick to make our first plot! Try entering this command and see what happens. It should plot these numbers against each other\n\n\n  x  y\n1 1  6\n2 2  7\n3 3  8\n4 4  9\n5 5 10\n\n\n\nplot(x= 1:5, y= 6:10,xlab=\"x-axis\",ylab=\"y-axis\")"
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#asking-questionscomparisons",
    "href": "in_S462_Tutorial3RBasics.html#asking-questionscomparisons",
    "title": "T3: Console-Basics and help",
    "section": "Asking questions/comparisons",
    "text": "Asking questions/comparisons\nWe can also do comparisons in R - using the special symbols TRUE or FALSE (no quote marks, they are special).\nHere we are asking R whether 1 is equal to 1.\n\n# note two equals signs is read as \"is equal to\"\n1 == 1  \n\n[1] TRUE\n\n\nWe could also have used\n\n!= “Not equal to”\n< “Less than”\n<= “Less than or equal to`\n> “Greater than”\n>= “Greater than or equal to”\n\nNow ask the computer if the number 12 is less than or equal to the number 10."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#Tut3C_plus",
    "href": "in_S462_Tutorial3RBasics.html#Tut3C_plus",
    "title": "T3: Console-Basics and help",
    "section": "The + symbol in the console",
    "text": "The + symbol in the console\nIf you type in an incomplete command, R will understand and wait for you to complete it. For example, if you type 1 + and press enter, R will know that you are not finished typing. So it will move onto the next line but the > will have changed into a +, which means its waiting for you to complete your command.\nIf you want to cancel a command you can simply hit the “Esc” key or press the little stop symbol and R studio will reset.\nPressing escape isn’t only useful for killing incomplete commands: you can also use it to tell R to stop running code (for example if it’s taking much longer than you expect), or to get rid of the code you’re currently writing."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#Tut3D_functions",
    "href": "in_S462_Tutorial3RBasics.html#Tut3D_functions",
    "title": "T3: Console-Basics and help",
    "section": "Functions/Commands",
    "text": "Functions/Commands\nWatch this short video to learn three important facts about functions:\n\n\n\n\n\n\n\n\n\nThe power of R lies in its many thousands of these built in commands, or functions. In fact, we have already come across one - the plot command. A function, or command is simply an action you can take - like pressing the square root button on a calculator.\nA command is always followed by parentheses ( ), inside which you put your “arguments” (e.g. the thing you want to take the square root of)\nTry typing these EXACTLY into the console.\n\nnchar(\"hello\")\n\nThis will count the number of letters in the word “hello” (e.g.\n\n\n\n\nfile.choose()\n\nThis will open up an interactive window (sometimes behind the studio screen), choose any file and it will print the location in the console. NOTE WE STILL NEED THE PARENTHESES, but there are no arguments so they are empty.\n\n\nTo understand what I mean about parentheses, try typing each of these commands exactly and see what happens.\n\n# Typing this into the console will print out the underlying code\nfile.choose \n\n# Typing it WITH parentheses will run the command. Note for this command, the parentheses are empty!  \nfile.choose()\n\n# Typing a ? in front will open the help file for that command in the help quadrant\n?file.choose\n\nSometimes we need to give the command some additional information as an argument. Anything we wish to tell the command should be included inside the inside the parentheses (separated by commas). The command literally only knows about the stuff inside the parentheses.\n\nsin(1) # trigonometry functions.  Apply the sine function to the number 1. \n\nlog(10) # natural logarithm.  Take the natural logarithm of the number 10. \n\nnchar(\"hello\") # Count the letters in the word hello\n\nWe can also add optional extra arguments. For example let’s improve our plot. This following command will plot the number 1 to 10 against the numbers 12 to 20, along with some axis labels. When you run this, the plot will show up in the plots tab.\n\n# plot the numbers 1 to 10 against the numbers 11 to 20\nplot(1:10,11:20,col=\"dark blue\", xlab=\"x values\",ylab=\"GEOG-364 is the best\") \n\n\n\n\nIf you are feeling lost, https://swcarpentry.github.io/r-novice-gapminder/01-rstudio-intro/ is a good website which goes over a lot of this in more detail."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#Tut3E_text",
    "href": "in_S462_Tutorial3RBasics.html#Tut3E_text",
    "title": "T3: Console-Basics and help",
    "section": "Dealing with text",
    "text": "Dealing with text\nIn R, the computer interprets most words as commands. But sometimes we need to actually input text, for example for a plot title. For the computer to understand text, you need quote marks. The computer will see anything without quote marks as a command.\nFor example, try typing print(\"Hello World\") into the console and the computer should just repeat it back to you.Forget about the quotes and this happens..\n\n\n\n\n\nYour screen after running the project\n\n\n\n\nYour first error. The “unexpected symbol” it’s talking about is the computer thinking that “Hello” and “world” must be two different commands, then getting confused by the space between Hello and World.."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#Tut3F_vars",
    "href": "in_S462_Tutorial3RBasics.html#Tut3F_vars",
    "title": "T3: Console-Basics and help",
    "section": "Variables",
    "text": "Variables\nSo now we can use R as a calculator and even add a few more complex commands. What we need to be able to do now is to save the results, or load in data so we can run more complex commands. We do this through assigning our results to a variable. By this I mean we save the results and give them a name, then in the future, instead of retyping the whole command, we simply type that name and R will recall the answer.\nThe symbol to store data into a variable is using the assignment arrow <-, which is made up of the left arrow and a dash. You can also use the equals sign, but it can cause complications later on. Try typing this command into the console:\n\nx <- 1/50\n\nNotice that pressing enter did not print a value onto your screen as it did earlier. Instead, look down at the environment tab, you should notice that an x has turned up, with the result next to it.\nSo our variable x is now associated with the value 0.02, or 1/50. You can print a variable on screen by typing its name, no quotes, or by using the print command. Try printing out your variable.\n\nx\n\n# or\n\nprint(x)\n\n# see what happens when you do this\n\nprint(\"x\")\n\nThis ‘x’ variable can be used in place of a number in any calculation that expects a number. Try typing\n\nlog(x)\n\n# this is now the same as \nlog(1/50)\n\nThe way R works is that first it looks for the commands on the right of the arrow. It runs all of them, calculates the result, then saves that result with the name on the left of the arrow. It does not save the command itself, just the answer. For example, in this case, R has no idea that x was created using maths, it just knows that it is equal to the number 0.02.\nNotice also that variables can be reassigned. Type this into your console.\n\nx <- 100\nprint(x)\n\nx used to contain the value 0.025 and and now it has the value 100.\nNote, the letter x isn’t special in any way, it’s just a variable name. You can replace it with any word you like as long as it contains no spaces and doesn’t begin with a number.\nfor example\n\nvlogbrothers.DFTBA <- \"Dont forget to be awesome\"\nprint(vlogbrothers.DFTBA)\n\nHow you name stuff is up to you, , but be consistent. Different people use different conventions for long variable names, these include\n\nperiods.between.words.1 (as you can see, I like this)\nunderscores_between_words\ncamelCaseToSeparateWords\n\nFinally, R IS CASE SENSITIVE. X and x are different variables! Try these and you will see both appear separately in your environment tab.\n\nh <- 1\nH <- 2\n\nans <- h+H\nprint(ans)\n\n\nprint(h)\n\n\nprint(H)\n\nTo delete a variable, you can use the rm() command e.g.\n\nrm(x)\n\nand to clear everything, type\n\nrm(list=ls())\n\n\nCombining variables\nAs I showed above, you can now use multiple variables together in more complex commands. For example, try these commands:\n\nx <- 2\n\n#Take the variable x, add 1 then save it to a new variable called y\ny <- x + 1 \n\n# print the multiple of 2yx onto the screen\nprint(2*y*x)\n\nNow you can see that there are two variables in your environment tab, x and y. Where y is the sum of the contents of x plus 1.\nYou can even use this to change your original variable . Try typing the code below in a few times into the console and see what happens.\nA short cut to do this is to type the commands the first time, then use the up-arrow on your keyboard to cycle back through previous commands you have typed\n\nx <- x + 1 # notice how RStudio updates its description of x in the environment tab\nx          # print the contents of \"x\" onto the screen\n\nOur variables don’t have to be numbers. They could refer to tables of data, or a spatial map, or any other complex thing. We will cover this more in future labs."
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#how-to-use-the-r-help-files",
    "href": "in_S462_Tutorial3RBasics.html#how-to-use-the-r-help-files",
    "title": "T3: Console-Basics and help",
    "section": "How to use the R help files",
    "text": "How to use the R help files\nHere’s how I approach it\n\nThe only info we NEED to know about a new command is its name and the library/package/app it is stored in. \n\n\n\nIf you don’t know, you can often google the command, and go to one of the websites with an online helpfile\nDifferent websites have different ways of writing the things. For example, here are four common files you might see when looking at the mutate command which is a part of the dplyr package.\n\n\n\n\n\n\nCOMMAND=mutate, PACKAGE=dplyr\n\n\n\n\n\n\n\n\n\nCOMMAND=mutate, PACKAGE=dplyr\n\n\n\n\n\n\n\n\n\nCOMMAND=mutate, PACKAGE=dplyr\n\n\n\n\n\n\nIf you need to install the package, go to the Packages menu in the quadrant and click install.\n\n\n\nAdd the library(PACKAGENAME) command to your library code chunk and run to load the package.\n\n\n\nImmediately go to the help file for the command you want to run. You can do this in the help menu next to the packages menu, or using a ? in the CONSOLE e.g. ?skim. This will not work if you have not loaded the library.\n\n\n\nInside every help file you will see this structure (SKIM THIS EXTERNAL: TUTORIAL)[https://bcgov.github.io/ds-cop-intro-to-r/seeking-help-in-r.html].\n\n\n\nFINALLY, Scroll to the bottom of the helpfile for some worked examples that you can literally copy and paste into your console or your code to understand how it works.\n\n\nHINT FOR LAB 2, SCROLL ALL THE WAY TO THE VERY BOTTOM OF THE HELP FILE"
  },
  {
    "objectID": "in_S462_Tutorial3RBasics.html#example-understanding-skim",
    "href": "in_S462_Tutorial3RBasics.html#example-understanding-skim",
    "title": "T3: Console-Basics and help",
    "section": "EXAMPLE! Understanding skim",
    "text": "EXAMPLE! Understanding skim\nI was told last year about a new summary command, skim. Here’s how it ended up in your lab instructions\n\nI googled ‘skim r command’. This took me quickly to the R documentation page\n\n\n\n\n\n\nLook for Rdocumentation, search-R-Project, or Rdrr\n\n\n\n\n\nI ended up at this website: https://search.r-project.org/CRAN/refmans/skimr/html/skim.html. From this I saw that the skim() command is in the skimr package*\n\n\n\n\n\n\nThe skim command is in the skimr package (red circle)\n\n\n\n\n\nI added the skimr package to my library code chunk and re-ran\n\n\n# LIBRARIES\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggpubr)\nlibrary(ggplot2)\nlibrary(plotly)\n\nlibrary(skimr) \n\n\nIn the console, I FIRST typed > ?skimr to read about the package itself (e.g. ?PACKAGENAME). This doesn’t work if you didn’t run the library code chunk first.\n\n\n\nIn the console, I THEN typed > ?skim to bring up the help file and scrolled to the bottom. This doesn’t work if you didn’t run the library code chunk first. Inside every R help file you will see this structure: https://bcgov.github.io/ds-cop-intro-to-r/seeking-help-in-r.html but for now, I scrolled to the bottom.\n\nI then ran the help file worked examples in the console to understand the command. It looks like skim is a nice summary command I can apply to a table (in their case the iris table). And that’s how it ended up here..\n\n\n skim(iris)\n\n\nData summary\n\n\nName\niris\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\n\n\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\n\n\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\n\n\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃\n\n\n\n\n # Use tidyselect\n skim(iris, Species)\n\n\nData summary\n\n\nName\niris\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\n\n\n\n\n skim(iris, starts_with(\"Sepal\"))\n\n\nData summary\n\n\nName\niris\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.8\n6.4\n7.9\n▆▇▇▅▂\n\n\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.0\n3.3\n4.4\n▁▆▇▂▁\n\n\n\n\n skim(iris, where(is.numeric))\n\n\nData summary\n\n\nName\niris\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\n\n\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\n\n\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\n\n\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃\n\n\n\n\n\n\n\nFinally, I googled tutorials to see if there was a friendlier way of looking: https://docs.ropensci.org/skimr/reference/skim.html"
  },
  {
    "objectID": "in_S462_Tutorial6Wrangling.html",
    "href": "in_S462_Tutorial6Wrangling.html",
    "title": "T6: Summaries filtering",
    "section": "",
    "text": "Here I will show a few examples for the houses dataset we were using in lectures\n\n\n\n\n\nTo have a look at the data there are many options. You can:\n\nclick on its name in the environment tab\nType its name into the console or into a code chunk (e.g. for our table, type piratedataset into the console or a code chunk)\nRun the command View(variable_name) (View is a command from the tidyverse package). This will open the data in a new tab.\nRun the command head(variable_name) to see the first 6 lines or so (good for quick checks)\nRun the command glimpse(variable_name) to get a nice summary.\nRun the command names(variable_name) to get the column names.\n\n\n\nFor example\n\n# Note, there are sometimes more columns to the right, use the arrow to see\nhead(HousesNY)\n\n  Price Beds Baths  Size  Lot\n1  57.6    3     2 0.960 1.30\n2 120.0    6     2 2.786 0.23\n3 150.0    4     2 1.704 0.27\n4 143.0    3     2 1.200 0.80\n5  92.5    3     1 1.329 0.42\n6  50.0    2     1 0.974 0.34\n\n\nTo see what the column names are, you can use the names(dataset) command\n\nnames(HousesNY)\n\n[1] \"Price\" \"Beds\"  \"Baths\" \"Size\"  \"Lot\"  \n\n\nOr the glimpse command:\n\nglimpse(HousesNY)\n\nRows: 53\nColumns: 5\n$ Price <dbl> 57.6, 120.0, 150.0, 143.0, 92.5, 50.0, 89.0, 140.0, 197.5, 125.1…\n$ Beds  <int> 3, 6, 4, 3, 3, 2, 2, 4, 4, 3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 3, 4, 4…\n$ Baths <dbl> 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.5, 2.0, 2.0, 1.0, 2.0,…\n$ Size  <dbl> 0.960, 2.786, 1.704, 1.200, 1.329, 0.974, 1.029, 2.818, 2.268, 1…\n$ Lot   <dbl> 1.30, 0.23, 0.27, 0.80, 0.42, 0.34, 0.29, 0.21, 1.00, 0.30, 1.30…\n\n\nTo see how many columns and rows there are, you can use the nrow() and ncol() commands\n\nnrow(HousesNY)\n\n[1] 53\n\nncol(HousesNY)\n\n[1] 5\n\n\n \n\n\n\nTo look at the summaries there are a load of options. Choose your favourites:\n\nsummary(dataset)\nskim(dataset) in the skimr package\nsummarize(dataset) in the papeR package. This looks pretty powerful, I’m just learning it\n\nNone are better or worse than others - simply choose what works for you in the moment.\n\nsummary(HousesNY)\n\n     Price            Beds           Baths            Size      \n Min.   : 38.5   Min.   :2.000   Min.   :1.000   Min.   :0.712  \n 1st Qu.: 82.7   1st Qu.:3.000   1st Qu.:1.500   1st Qu.:1.296  \n Median :107.0   Median :3.000   Median :2.000   Median :1.528  \n Mean   :113.6   Mean   :3.396   Mean   :1.858   Mean   :1.678  \n 3rd Qu.:141.0   3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:2.060  \n Max.   :197.5   Max.   :6.000   Max.   :3.500   Max.   :3.100  \n      Lot        \n Min.   :0.0000  \n 1st Qu.:0.2700  \n Median :0.4200  \n Mean   :0.7985  \n 3rd Qu.:1.1000  \n Max.   :3.5000  \n\n\n\nlibrary(skimr) # you would need to install this\nskim(HousesNY)\n\n\nData summary\n\n\nName\nHousesNY\n\n\nNumber of rows\n53\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPrice\n0\n1\n113.63\n41.43\n38.50\n82.70\n107.00\n141.00\n197.5\n▃▇▅▃▃\n\n\nBeds\n0\n1\n3.40\n0.79\n2.00\n3.00\n3.00\n4.00\n6.0\n▂▇▆▁▁\n\n\nBaths\n0\n1\n1.86\n0.65\n1.00\n1.50\n2.00\n2.00\n3.5\n▅▇▁▁▁\n\n\nSize\n0\n1\n1.68\n0.60\n0.71\n1.30\n1.53\n2.06\n3.1\n▃▇▅▂▂\n\n\nLot\n0\n1\n0.80\n0.76\n0.00\n0.27\n0.42\n1.10\n3.5\n▇▃▂▁▁\n\n\n\n\n\n\nlibrary(pillar) # you would need to install this\n\n\nAttaching package: 'pillar'\n\n\nThe following object is masked from 'package:dplyr':\n\n    dim_desc\n\nglimpse(HousesNY)\n\nRows: 53\nColumns: 5\n$ Price <dbl> 57.6, 120.0, 150.0, 143.0, 92.5, 50.0, 89.0, 140.0, 197.5, 125.1…\n$ Beds  <int> 3, 6, 4, 3, 3, 2, 2, 4, 4, 3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 3, 4, 4…\n$ Baths <dbl> 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.5, 2.0, 2.0, 1.0, 2.0,…\n$ Size  <dbl> 0.960, 2.786, 1.704, 1.200, 1.329, 0.974, 1.029, 2.818, 2.268, 1…\n$ Lot   <dbl> 1.30, 0.23, 0.27, 0.80, 0.42, 0.34, 0.29, 0.21, 1.00, 0.30, 1.30…\n\n\nor\n\nstr(HousesNY)\n\n'data.frame':   53 obs. of  5 variables:\n $ Price: num  57.6 120 150 143 92.5 ...\n $ Beds : int  3 6 4 3 3 2 2 4 4 3 ...\n $ Baths: num  2 2 2 2 1 1 2 3 2.5 2 ...\n $ Size : num  0.96 2.79 1.7 1.2 1.33 ...\n $ Lot  : num  1.3 0.23 0.27 0.8 0.42 0.34 0.29 0.21 1 0.3 ...\n\n\nTo see what the column names are, you can use the names(dataset) command\n\nnames(HousesNY)\n\n[1] \"Price\" \"Beds\"  \"Baths\" \"Size\"  \"Lot\"  \n\n\nTo print the first few rows\n\nhead(HousesNY)\n\n  Price Beds Baths  Size  Lot\n1  57.6    3     2 0.960 1.30\n2 120.0    6     2 2.786 0.23\n3 150.0    4     2 1.704 0.27\n4 143.0    3     2 1.200 0.80\n5  92.5    3     1 1.329 0.42\n6  50.0    2     1 0.974 0.34\n\n\nTo find the number of rows and columns\n\nnrow(HousesNY)\n\n[1] 53\n\nncol(HousesNY)\n\n[1] 5\n\n#or both dimensions\ndim(HousesNY)\n\n[1] 53  5\n\n\nOr you can do things manually, using the $ symbol to choose a column. All of this is for the price column\n\nmean(HousesNY$Price)\n\n[1] 113.6321\n\nmedian(HousesNY$Price)\n\n[1] 107\n\nmode(HousesNY$Price)\n\n[1] \"numeric\"\n\nsd(HousesNY$Price)\n\n[1] 41.43006\n\nvar(HousesNY$Price)\n\n[1] 1716.45\n\nIQR(HousesNY$Price)\n\n[1] 58.3\n\nrange(HousesNY$Price)\n\n[1]  38.5 197.5"
  },
  {
    "objectID": "in_S462_Tutorial6Wrangling.html#selecting-a-specific-column",
    "href": "in_S462_Tutorial6Wrangling.html#selecting-a-specific-column",
    "title": "T6: Summaries filtering",
    "section": "Selecting a specific column",
    "text": "Selecting a specific column\nHere I am using the NYHouses data as an example. Sometimes we want to deal with only one specific column in our spreadsheet/dataframe, for example applying the mean/standard deviation/inter-quartile range command to say just the Price column.\nTo do this, we use the $ symbol. For example, here I’m simply selecting the data in the elevation column only and saving it to a new variable called elevationdata.\n\ndata(\"HousesNY\")\nprice <- HousesNY$Price\n\nprice\n\nTry it yourself. You should have seen that as you typed the $, it gave you all the available column names to choose from.\nThis means we can now easily summarise specific columns. For example:\n\nsummary(HousesNY) will create a summary of the whole spreadsheet,\nsummary(HousesNY$Price) will only summarise the Price column.\n\nmean(HousesNY$Price) will take the mean of the Price column in the HousesNY dataframe."
  },
  {
    "objectID": "in_S462_Tutorial6Wrangling.html#Tut7b_table",
    "href": "in_S462_Tutorial6Wrangling.html#Tut7b_table",
    "title": "T6: Summaries filtering",
    "section": "Table command: counts per group",
    "text": "Table command: counts per group\nSometimes we want to count the occurrences of some category in our dataset. For example, if you look at the HousesNY, it might be interesting to know how many Houses had each number of bedrooms\nTo do this, we use the table command:\n\ntable(HousesNY$Beds)\n\nor to see the number with each combination of bedrooms and bathrooms:\n\ntable(HousesNY$Beds, HousesNY$Baths)\n\nFor more, this tutorial is excellent: https://www.cyclismo.org/tutorial/R/tables.html."
  },
  {
    "objectID": "in_S462_Tutorial6Wrangling.html#group_by-command-statistics-per-group",
    "href": "in_S462_Tutorial6Wrangling.html#group_by-command-statistics-per-group",
    "title": "T6: Summaries filtering",
    "section": "“Group_by” command: statistics per group",
    "text": "“Group_by” command: statistics per group\nWhat if we want to do more than just count the number of rows?\nWell, we can use the group_by() and summarise() commands and save our answers to a new variable.\nHere we are making use of the pipe symbol, %>%, which takes the answer from group_by and sends it directly to the summarise command.\nHere is some data on frost dates at weather stations.\n\nfrost    <- readxl::read_excel(\"Data_frostdata.xlsx\")\nhead(frost)\n\n# A tibble: 6 × 8\n  Station    State Type_Fake Avg_DOY_SpringFrost Latit…¹ Longi…² Eleva…³ Dist_…⁴\n  <chr>      <chr> <chr>                   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Valley     AL    City                    110.     34.6   -85.6    1020  295.  \n2 Union      AL    City                     82.3    32.0   -85.8     440  122.  \n3 Saint      AL    Airport                  99.8    34.2   -86.8     800  252.  \n4 Fernandina FL    City                     46.9    30.7   -81.5      13    1.15\n5 Lake       FL    City                     60.6    30.2   -82.6     195   63.0 \n6 West       GA    City                     85.6    32.9   -85.2     575  187.  \n# … with abbreviated variable names ¹​Latitude, ²​Longitude, ³​Elevation,\n#   ⁴​Dist_to_Coast\n\n\nTo summarise results by the type of weather station:\n\nfrost.summary.type <- group_by(frost, by=Type_Fake) %>%\n                          summarise(mean(Latitude),\n                                    max(Latitude),\n                                    min(Dist_to_Coast))\nfrost.summary.type\n\n# A tibble: 3 × 4\n  by                            `mean(Latitude)` `max(Latitude)` min(Dist_to_C…¹\n  <chr>                                    <dbl>           <dbl>           <dbl>\n1 Agricultural_Research_Station             33.7            36.3            4.95\n2 Airport                                   34.4            37.3           45.4 \n3 City                                      33.7            36.5            1.15\n# … with abbreviated variable name ¹​`min(Dist_to_Coast)`\n\n\nHere, my code is:\n\nSplitting up the frost data by the Type_Fake column(e.g. one group for City, one for Airport and one for Agricultural Research)\nFor the data rows in each group, calculating the mean latitude, the maximum latitude and the minimum distance to the coast\nSaving the result to a new variable called frost.summary.type.\nPrinting the results on the screen e.g. the furthest North/maximum latitude of rows tagged Agricultural_Research_Station is 36.32 degrees."
  },
  {
    "objectID": "in_S462_Tutorial6Wrangling.html#filtering-rows-and-columns",
    "href": "in_S462_Tutorial6Wrangling.html#filtering-rows-and-columns",
    "title": "T6: Summaries filtering",
    "section": "Filtering rows and columns",
    "text": "Filtering rows and columns\nSometimes, we do not want to analyse at the entire data.frame. Instead, we would like to only look at one (or more) columns or rows.\nThere are several ways we can select data.\n\nTo choose a specific column, we can use the $ symbol to select its name (as described above)\nIf you know which number rows or columns you want, you can use square brackets to numerically select data.\n\nEssentially our data follows the format: tablename[ROWS,COLUMNS]\n\n# This will select the data in the 5th row and 7th column\nfrost[5,7]\n\n# A tibble: 1 × 1\n  Elevation\n      <dbl>\n1       195\n\n# This will select the 2nd row and ALL the columns \nfrost[2,]\n\n# A tibble: 1 × 8\n  Station State Type_Fake Avg_DOY_SpringFrost Latitude Longitude Eleva…¹ Dist_…²\n  <chr>   <chr> <chr>                   <dbl>    <dbl>     <dbl>   <dbl>   <dbl>\n1 Union   AL    City                     82.3     32.0     -85.8     440    122.\n# … with abbreviated variable names ¹​Elevation, ²​Dist_to_Coast\n\n# This will select the 3rd column and ALL the rows\nfrost[,3]\n\n# A tibble: 76 × 1\n   Type_Fake                    \n   <chr>                        \n 1 City                         \n 2 City                         \n 3 Airport                      \n 4 City                         \n 5 City                         \n 6 City                         \n 7 City                         \n 8 City                         \n 9 Agricultural_Research_Station\n10 Agricultural_Research_Station\n# … with 66 more rows\n\n# similar to using its name\nfrost$Type_Fake\n\n [1] \"City\"                          \"City\"                         \n [3] \"Airport\"                       \"City\"                         \n [5] \"City\"                          \"City\"                         \n [7] \"City\"                          \"City\"                         \n [9] \"Agricultural_Research_Station\" \"Agricultural_Research_Station\"\n[11] \"Agricultural_Research_Station\" \"Airport\"                      \n[13] \"Airport\"                       \"City\"                         \n[15] \"City\"                          \"Airport\"                      \n[17] \"City\"                          \"Airport\"                      \n[19] \"City\"                          \"Airport\"                      \n[21] \"City\"                          \"City\"                         \n[23] \"City\"                          \"Airport\"                      \n[25] \"Agricultural_Research_Station\" \"City\"                         \n[27] \"City\"                          \"City\"                         \n[29] \"Airport\"                       \"Agricultural_Research_Station\"\n[31] \"Airport\"                       \"City\"                         \n[33] \"City\"                          \"City\"                         \n[35] \"Airport\"                       \"Agricultural_Research_Station\"\n[37] \"City\"                          \"City\"                         \n[39] \"City\"                          \"Agricultural_Research_Station\"\n[41] \"Agricultural_Research_Station\" \"City\"                         \n[43] \"City\"                          \"Airport\"                      \n[45] \"Airport\"                       \"Airport\"                      \n[47] \"Agricultural_Research_Station\" \"City\"                         \n[49] \"City\"                          \"City\"                         \n[51] \"City\"                          \"Agricultural_Research_Station\"\n[53] \"Agricultural_Research_Station\" \"Agricultural_Research_Station\"\n[55] \"Airport\"                       \"City\"                         \n[57] \"Airport\"                       \"City\"                         \n[59] \"Airport\"                       \"City\"                         \n[61] \"Agricultural_Research_Station\" \"Airport\"                      \n[63] \"Agricultural_Research_Station\" \"City\"                         \n[65] \"City\"                          \"City\"                         \n[67] \"City\"                          \"Airport\"                      \n[69] \"Airport\"                       \"Agricultural_Research_Station\"\n[71] \"Airport\"                       \"City\"                         \n[73] \"Airport\"                       \"Airport\"                      \n[75] \"City\"                          \"Agricultural_Research_Station\"\n\n# We can combine our commands, this will print the 13th row of the Longitude column \n# (no comma as we're only looking at one column)\nfrost$Longitude[13]\n\n[1] -82.58\n\n# The : symbol lets you choose a sequence of numbers e.g. 1:5 is 1 2 3 4 5\n# So this prints out rows 11 to 15 and all the columns\nfrost[11:15,]\n\n# A tibble: 5 × 8\n  Station  State Type_Fake               Avg_D…¹ Latit…² Longi…³ Eleva…⁴ Dist_…⁵\n  <chr>    <chr> <chr>                     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Winthrop SC    Agricultural_Research_…    87.2    34.9   -81.0     690   149. \n2 Little   SC    Airport                    87.7    34.2   -81.4     711   131. \n3 Calhoun  SC    Airport                    91.5    34.1   -82.6     530   164  \n4 Clemson  SC    City                       93.6    34.7   -82.8     824   202. \n5 De       FL    City                       71.3    30.7   -86.1     245    29.4\n# … with abbreviated variable names ¹​Avg_DOY_SpringFrost, ²​Latitude,\n#   ³​Longitude, ⁴​Elevation, ⁵​Dist_to_Coast\n\n# The \"c\" command allows you to enter whatever numbers you like.  \n# So this will print out rows 4,3,7 and the \"Elevation\" and \"Dist_to_Coast\" columns\nfrost[c(4,3,7), c(\"Elevation\",\"Dist_to_Coast\")]\n\n# A tibble: 3 × 2\n  Elevation Dist_to_Coast\n      <dbl>         <dbl>\n1        13          1.15\n2       800        252.  \n3       500        132.  \n\n\nYou can also add questions and commands inside the square brackets. For example here is the weather station with the lowest elevation. You can see my command chose BOTH rows where elevation = 10.\n\n# which row has the lowest elevation\n# note the double == (more below)\nrow_number <- which(frost$Elevation == min(frost$Elevation))\n\n# choose that row\nloweststtation <- frost[row_number ,  ]\nloweststtation\n\n# A tibble: 2 × 8\n  Station     State Type_Fake            Avg_D…¹ Latit…² Longi…³ Eleva…⁴ Dist_…⁵\n  <chr>       <chr> <chr>                  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Charlestown SC    Agricultural_Resear…    84.6    32.8   -79.9      10    4.95\n2 Edenton     NC    City                    85.3    36.0   -76.6      10    1.25\n# … with abbreviated variable names ¹​Avg_DOY_SpringFrost, ²​Latitude,\n#   ³​Longitude, ⁴​Elevation, ⁵​Dist_to_Coast\n\n\n\nseaside <- frost[which(frost$Dist_to_Coast < 10) ,  ]\nseaside\n\n# A tibble: 5 × 8\n  Station     State Type_Fake            Avg_D…¹ Latit…² Longi…³ Eleva…⁴ Dist_…⁵\n  <chr>       <chr> <chr>                  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Fernandina  FL    City                    46.9    30.7   -81.5      13    1.15\n2 Charlestown SC    Agricultural_Resear…    84.6    32.8   -79.9      10    4.95\n3 Edenton     NC    City                    85.3    36.0   -76.6      10    1.25\n4 Southport   NC    City                    82.8    33.9   -78.0      20    3.42\n5 Brunswick   GA    Agricultural_Resear…    48.4    31.2   -81.5      13    7.18\n# … with abbreviated variable names ¹​Avg_DOY_SpringFrost, ²​Latitude,\n#   ³​Longitude, ⁴​Elevation, ⁵​Dist_to_Coast"
  },
  {
    "objectID": "in_S462_Tutorial6Wrangling.html#which-command",
    "href": "in_S462_Tutorial6Wrangling.html#which-command",
    "title": "T6: Summaries filtering",
    "section": "which command",
    "text": "which command\nThe which command essentially says “which numbers” meet a certain threshold\ne,g,\n\na <- 100:110\nwhich(a > 107)\n\n[1]  9 10 11\n\n\nOr which rows:\n\noutlier_rows <- which(frost$Dist_to_Coast < 1.5)\n\n\nDeleting rows\nOr if you know the row number you can use the minus - sign to remove. Or just filter below.\n\n# remove row 6 and and overwrite\nfrost <- frost[-6 ,]\n\n# remove columns 4 and 2 and save result to newdata and overwrite\nnewdata <- frost[, - c(2,4) ]\n\n\n\nThe dplyr filter command (tidyverse)\nFiltering means selecting rows/observations based on their values. To filter in R, use the command filter() from the dplyr package. I tend to write it as dplyr:filter() to force it to be correct.\nHere we can apply the filter command to choose specific rows that meet certain criteria\n\nfilter(frost, State == \"FL\")\n\nThe double equal operator == means equal to. The command is telling R to keep the rows in frost where the State column equals “FL”.\nIf you want a few categories, choose the %in% operator, using the c() command to stick together the categories you want. For example, here are states in Florida and Virginia.\n\nfilter(frost, State %in% c(\"FL\",\"VA\"))\n\nWe can also explicitly exclude cases and keep everything else by using the not equal operator !=. The following code excludes airport stations.\n\nfilter(frost, Type_Fake != \"Airport\")\n\nWhat about filtering if a row has a value greater than a specified value? For example, Stations with an elevation greater than 500 feet?\n\nfilter(frost, Elevation > 500)\n\nOr less-than-or-equal-to 200 feet.\n\n# or save the result to a new variable\nlowland_stations <- filter(frost, Elevation < 200)\nsummary(lowland_stations)\n\n\nIn addition to comparison operators, filtering may also utilize logical operators that make multiple selections. There are three basic logical operators: & (and), | (or), and ! (not). We can keep Stations with an Elevation greater than 300 and State in Alabama &.\n\nfilter(frost, Elevation > 300 & State == \"AL\")\n\nUse | to keep Stations with a Type_Fake of “Airport” or a last spring frost date after April (~ day 90 of the year).\n\nfilter(frost, Type_Fake == \"Airport\" | Avg_DOY_SpringFrost > 90 )\n\n\n\nThe dplyr arrange command (tidyverse)\n\n\nWe use the arrange() function to sort a data frame by one or more variables. You might want to do this to get a sense of which cases have the highest or lowest values in your data set or sort counties by their name. For example, let’s sort in ascending order by elevation.\n\narrange(frost, Latitude)\n\n# A tibble: 75 × 8\n   Station     State Type_Fake           Avg_D…¹ Latit…² Longi…³ Eleva…⁴ Dist_…⁵\n   <chr>       <chr> <chr>                 <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Inverness   FL    City                   50.6    28.8   -82.3      40   20.5 \n 2 Ocala       FL    City                   52.7    29.2   -82.1      75   41.6 \n 3 Lake        FL    City                   60.6    30.2   -82.6     195   63.0 \n 4 Tallahassee FL    Agricultural_Resea…    75.8    30.4   -84.4      55   23.2 \n 5 Fernandina  FL    City                   46.9    30.7   -81.5      13    1.15\n 6 De          FL    City                   71.3    30.7   -86.1     245   29.4 \n 7 Quitman     GA    City                   65.5    30.8   -83.6     185   56.4 \n 8 Brunswick   GA    Agricultural_Resea…    48.4    31.2   -81.5      13    7.18\n 9 Waycross    GA    Agricultural_Resea…    75.9    31.2   -82.3     145   52.4 \n10 Tifton      GA    City                   87.3    31.4   -83.5     380  101.  \n# … with 65 more rows, and abbreviated variable names ¹​Avg_DOY_SpringFrost,\n#   ²​Latitude, ³​Longitude, ⁴​Elevation, ⁵​Dist_to_Coast\n\n\nBy default, arrange() sorts in ascending order. We can sort by a variable in descending order by using the desc() function on the variable we want to sort by. For example, to sort the dataframe by Avg_DOY_SpringFrost in descending order we use\n\narrange(frost, desc(Avg_DOY_SpringFrost))\n\n# A tibble: 75 × 8\n   Station        State Type_Fake        Avg_D…¹ Latit…² Longi…³ Eleva…⁴ Dist_…⁵\n   <chr>          <chr> <chr>              <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Marshall       NC    Airport             118.    35.8   -82.7    2000   258. \n 2 Highlands      NC    Agricultural_Re…    118.    35.0   -83.2    3333   235. \n 3 Mt             NC    City                113.    36.5   -80.6    1041   216. \n 4 Louisburg      NC    City                113.    36.1   -78.3     260    88.5\n 5 Rocky          VA    Airport             111.    37.0   -79.9    1315   180. \n 6 Henderson      NC    Agricultural_Re…    111.    36.3   -78.4     512    97.9\n 7 Farmville      VA    Airport             111.    37.3   -78.4     450    97.1\n 8 Statesville    NC    City                110.    35.8   -80.9     951   185. \n 9 Valley         AL    City                110.    34.6   -85.6    1020   295. \n10 Hendersonville NC    Agricultural_Re…    110.    35.3   -82.4    2160   227. \n# … with 65 more rows, and abbreviated variable names ¹​Avg_DOY_SpringFrost,\n#   ²​Latitude, ³​Longitude, ⁴​Elevation, ⁵​Dist_to_Coast"
  },
  {
    "objectID": "in_S462_Tutorial9Correlation.html",
    "href": "in_S462_Tutorial9Correlation.html",
    "title": "T9: Correlation",
    "section": "",
    "text": "See the scatterplot tutorial! Also covers adding lines of best fit etc."
  },
  {
    "objectID": "in_S462_Tutorial9Correlation.html#standard-regression-output",
    "href": "in_S462_Tutorial9Correlation.html#standard-regression-output",
    "title": "T9: Correlation",
    "section": "“Standard” regression output",
    "text": "“Standard” regression output\nThe command to do this is lm() e.g. linear model.\n\noutput <- lm(y_column ~ x_column,data=tablename)\noutput\n\nNOTE, THE WEIRD ~ SYMBOL. This means “depends on” and it’s how we tell R what the response variable is. E.g. y depends on x, or y=mx+c.\nFor example for the NYHouses data, it would be\n\n# response = Price, predictor = Lot size\nModel1.lm <- lm(Price ~ Lot,data=HousesNY)\nModel1.lm\n\n\nCall:\nlm(formula = Price ~ Lot, data = HousesNY)\n\nCoefficients:\n(Intercept)          Lot  \n   114.0911      -0.5749  \n\n\nSo we are saying here that the equation is\nExpected_Average_Price = -0.5749*Lot_Size + 114.0911\nE.g. the average expected price house with no Lot/Garden is 114.09\n\nPrinting out the equation\nYou can also directly get the code for the model equation by the equatiomatic package\n\n# YOU MIGHT NEED TO INSTALL THIS PACKAGE (SEE THE TUTORIAL)\nlibrary(equatiomatic)\nextract_eq(Model1.lm,use_coefs=FALSE)\n\nTo make it print out directly, put “asis=TRUE” as a code chunk option e.g. this code\n\n\n\n\n\nSee the asis in the top, this prints the output directly when you knit\n\n\n\n\nTurns into this:\n\nlibrary(equatiomatic)\nextract_eq(Model1.lm,use_coefs=FALSE)\n\n\\[\n\\operatorname{Price} = \\alpha + \\beta_{1}(\\operatorname{Lot}) + \\epsilon\n\\]\n\n\nYou can also look at the summary by looking at the summary command:\n\nsummary(Model1.lm)\n\n\nCall:\nlm(formula = Price ~ Lot, data = HousesNY)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-74.775 -30.201  -5.941  27.070  83.984 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 114.0911     8.3639  13.641   <2e-16 ***\nLot          -0.5749     7.6113  -0.076     0.94    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 51 degrees of freedom\nMultiple R-squared:  0.0001119, Adjusted R-squared:  -0.01949 \nF-statistic: 0.005705 on 1 and 51 DF,  p-value: 0.9401\n\n\nIn both cases, we have an estimate of the intercept (0.6386) and of the gradient (-13.8103). We will discuss the other values in later labs/lectures.\nNow let’s see how to add the regression line to our scatterplot. We can do this using abline(REGRESSION_VARIABLE), where regression_variable is the name of the variable you saved the output of lm to. For example.\n\nplot(HousesNY$Price ~ HousesNY$Lot)\nabline(lm(Price ~ Lot,data=HousesNY),col=\"blue\",lwd=1) \n\n\n\n\nFor more professional plots, see the scatterplots tutorial"
  },
  {
    "objectID": "in_S462_Tutorial9Correlation.html#better-olsrr-regression-output",
    "href": "in_S462_Tutorial9Correlation.html#better-olsrr-regression-output",
    "title": "T9: Correlation",
    "section": "“Better” OLSRR regression output",
    "text": "“Better” OLSRR regression output\nIf you want a different way of seeing the same output, you can use the ols_regress() command inside the olsrr package.\n\nlibrary(olsrr)\n\n\nAttaching package: 'olsrr'\n\n\nThe following object is masked from 'package:equatiomatic':\n\n    hsb\n\n\nThe following object is masked from 'package:datasets':\n\n    rivers\n\nModel1.lm.ols <- ols_regress(Price ~ Lot,data=HousesNY)\nModel1.lm.ols\n\n                          Model Summary                           \n-----------------------------------------------------------------\nR                        0.011       RMSE                 41.832 \nR-Squared                0.000       Coef. Var            36.813 \nAdj. R-Squared          -0.019       MSE                1749.910 \nPred R-Squared          -0.068       MAE                  34.152 \n-----------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                               ANOVA                                 \n--------------------------------------------------------------------\n                 Sum of                                             \n                Squares        DF    Mean Square      F        Sig. \n--------------------------------------------------------------------\nRegression        9.983         1          9.983    0.006    0.9401 \nResidual      89245.412        51       1749.910                    \nTotal         89255.395        52                                   \n--------------------------------------------------------------------\n\n                                    Parameter Estimates                                     \n-------------------------------------------------------------------------------------------\n      model       Beta    Std. Error    Std. Beta      t        Sig       lower      upper \n-------------------------------------------------------------------------------------------\n(Intercept)    114.091         8.364                 13.641    0.000     97.300    130.882 \n        Lot     -0.575         7.611       -0.011    -0.076    0.940    -15.855     14.705 \n-------------------------------------------------------------------------------------------\n\n\nThe ols_regress command produces beautiful output, but sometimes it doesn’t work well with other commands. So I tend to run a lm command at the same time to have both available.\nSometimes, this command can produce a weird error:\n\n\n\n\n\nThis is probably because you loaded the moderndive package\n\n\n\n\nThis is probably because you loaded the moderndive package. They do not play nicely together. Save your work, restart R and do not run any line that says library(moderndive)!."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT-462 Lab Book",
    "section": "",
    "text": "Welcome!\nThis is your home for all your instructions, labs, tutorials and projects.\nYou can find the class syllabus here: https://psu.instructure.com/courses/2243429/assignments/syllabus\nLook at the tabs to find:\n\nTutorials (constantly updated)\nYour Lab Overview & Labs\n\nProject Space\n\nThis book is made using R-Markdown and Quarto Websites. If you want to learn more, visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "in_S462_Tutorial8Plots.html",
    "href": "in_S462_Tutorial8Plots.html",
    "title": "T8: Making plots",
    "section": "",
    "text": "There are three places I visit constantly:\n\nhttps://www.r-graph-gallery.com/\nhttps://indrajeetpatil.github.io/ggstatsplot/\nhttps://r-charts.com/distribution/\nhttps://flowingdata.com/\n\nFor plots, we have many choices. We can use what is built into R, or.. use the ggplot system where you add on layers to your plot using the + symbol, or use specialist packages such as ggstatplot or beeswarm.\nIf you are new to data visualisation, read these two articles\n\nhttps://flowingdata.com/2014/10/23/moving-past-default-charts/\nhttps://flowingdata.com/2012/05/15/how-to-visualize-and-compare-distributions/\n\n\n\nPlots are designed to do two things, allow you to see something in the data that you couldn’t see in the numbers, plus communicate output in a compelling way. Going beyond the basics or knowing the limitations of a plot will help you do this, so in these examples I have provided a range of complexity.\nSo far, I have focused on plots that slow you to visualise the distribution of your response variable. You do not need to use them all! Choose ones that work for you and your data.\n\nBoxplots\nHistograms\nViolin plots (half boxplot half histogram)\nBeeswarm\n\n\n\n\nBoxplots have been around over 40 years! See their history and evolution here: http://vita.had.co.nz/papers/boxplots.pdf\nIn terms of your reports, you need to think of 3 things: - Why you are making the plot (quick look vs publication worthy final graphic) - What aspects of the data do you want to highlight (lots of data, comparing groups, weird distributions..) - What are your final requirements and personal style (colorblind friendly, you’re drawn to a certain type of plot..)\nSo for boxplots.. they are especially good at allowing you to compare different groups of things or to look for multiple groups in a single response variable. Here is a beautiful example made by Marcus Beckman on dissertation lengths.\nhttps://beckmw.wordpress.com/2014/07/15/average-dissertation-and-thesis-length-take-two/ and code here: https://github.com/fawda123/diss_proc )\nIf there are only one or two variables, I often jump to the violin or histogram plots as they show more detail.\nSo.. how to make these yourselves. You have a range of options!\n\n\nHere is the most basic boxplot you can make. I often start with this for my own use when exploring the data, then later decide which plots to “make pretty”.\n\nboxplot(HousesNY$Price)\n\n\n\n\nWe can make better boxplots in base R (e.g. using no special packages/libraries). See this tutorial for all the details: https://www.datamentor.io/r-programming/box-plot/ which goes through exactly what each line means.\n\n# one big command on separate lines\nboxplot(HousesNY$Price,\n        main = \"House prices of Canton NY sample\",\n        xlab = \"Price (Thousand USD)\",\n        col = \"light blue\",\n        border = \"dark blue\",\n        horizontal = TRUE,\n        notch = TRUE)\n\n\n\n\nThere are specific plotting packages, the most famous being ggplot2 (there are data camp courses on it). The absolute basics. Here x is blank because we just want to look at the price column alone.\n\nlibrary(ggplot2)\n\nggplot(HousesNY, aes(x =\"\", y = Price)) +    ## this loads the data\n   geom_boxplot()                            ## and we choose a boxplot\n\n\n\n\nNote for now, think of the %>% symbol and + symbol also as “one command on multiple lines..”. They allow you to build up layers of the plot. Data camp has more on this.\nBut with these we can easily do more sophisticated things. For example, here’s how to see the underlying data, which allows us to see something of the background distribution\nhttps://r-charts.com/distribution/box-plot-jitter-ggplot2/\n\n# Basic box plot\nggplot(HousesNY, aes(x = \"\", y = Price)) + \n  geom_boxplot() +\n  geom_jitter()\n\n\n\n\n\n\n\nThe basic code to see a boxplot split by group, in this case the price per number of beds:\n\nboxplot(HousesNY$Price ~ HousesNY$Beds)\n\n\n\n\nThe advantage of this is that you can be sure that you really did plot your columns of choice (e.g. you didn’t mistakenly label anything). Note, if you use a comma, rather than the “~” symbol, you will make one for each column - which is normally not useful!\n\nboxplot(HousesNY$Price,  HousesNY$Beds)\n\n\n\n\n\nIn GGplot comparing different groups:\n\n# Libraries\nlibrary(tidyverse)\nlibrary(hrbrthemes)\n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n\n\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n\n\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\nlibrary(viridis)\n\nLoading required package: viridisLite\n\n# tell R that the beds column is categorical\nHousesNY$Beds <- factor(HousesNY$Beds,\n                     levels=c(min(HousesNY$Beds):max(HousesNY$Beds)))\n\n# Plot\n  ggplot(HousesNY, aes(x=Beds, y=Price)) +\n    geom_boxplot() \n\n\n\n\nOr getting more complex\n\n# Libraries\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(viridis)\n\n# tell R that the beds column is categorical\n# I already did this in the table section\n#HousesNY$Beds <- as.factor(HousesNY$Beds)\n\n# Plot\nHousesNY %>%\n  ggplot( aes(x=Beds, y=Price, fill=Beds) )+\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    geom_jitter(color=\"black\", size=0.5, alpha=0.8) +\n    ggtitle(\"\") +\n    xlab(\"Beds\")\n\n\n\n\nor dotplots..\n\nggplot(HousesNY,  aes(x=Beds, y=Price, fill=Beds)) +\n  geom_boxplot() +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", dotsize = 0.5,binwidth=7)\n\n\n\n\nThere are MANY more options, plus code here: https://www.r-graph-gallery.com/boxplot.html\nand a delightful tutorial here: https://www.r-bloggers.com/2021/11/how-to-make-stunning-boxplots-in-r-a-complete-guide-with-ggplot2/\n\n\n\nFinally, we can get super fancy in base R - it’s often a good way to learn how to code. I like this example because it shows many different aspects/useful commands in R programming. http://www.opiniomics.org/beautiful-boxplots-in-base-r/\n\nlibrary(RColorBrewer)\n\n# create colours and colour matrix (for points)\nm     <- as.matrix(HousesNY$Price)\n\ncol_main   <- colorRampPalette(brewer.pal(12, \"Set3\"), alpha=TRUE)(ncol(m))\ncol_transp <- colorspace::adjust_transparency(col_main, alpha = .3)\n\ncolsm   <-matrix(rep(col_main, each=nrow(m)), ncol=ncol(m))\ncolsm_tr <-matrix(rep(col_transp, each=nrow(m)), ncol=ncol(m))\n\n\n# create some random data for jitter\nr <-  (matrix(runif(nrow(m)*ncol(m)), nrow=nrow(m), ncol=ncol(m)) / 2) - 0.25\n\n# get the greys (stolen from https://github.com/zonination/perceptions/blob/master/percept.R)\npalette <- brewer.pal(\"Greys\", n=9)\ncolor.background = palette[2]\ncolor.grid.major = palette[5]\n\n# set graphical area\npar(bty=\"n\", bg=palette[2], mar=c(5,8,3,1))\n\n# plot initial boxplot\nboxplot(m~col(m), horizontal=TRUE, outline=FALSE, lty=1, \n        staplewex=0, boxwex=0.8, boxlwd=1, medlwd=1, \n        col=colsm_tr, xaxt=\"n\", yaxt=\"n\",xlab=\"\",ylab=\"\")\n\n# plot gridlines\nfor (i in pretty(m,10)) {\n    lines(c(i,i), c(0,20), col=palette[4])\n}\n\n# plot points\npoints(m, col(m)+r, col=colsm, pch=16)\n\n# overlay boxplot\nboxplot(m~col(m), horizontal=TRUE, outline=FALSE, lty=1, \n        staplewex=0, boxwex=0.8, boxlwd=1, medlwd=1, col=colsm_tr, \n        add=TRUE, xaxt=\"n\", yaxt=\"n\")\n\n# add axes and title\naxis(side=1, at=pretty(m,10), col.axis=palette[7], \n     cex.axis=0.8, lty=0, tick=NA, line=-1)\naxis(side=1, at=50, labels=\"Price (Thousand USD)\", \n     lty=0, tick=NA, col.axis=palette[7])\naxis(side=2, at=1, col.axis=palette[7], cex.axis=0.8, \n     lty=0, tick=NA, labels=\"Sample 1\", las=2)\naxis(side=2, at=17/2, labels=\"Phrase\", col.axis=palette[7], \n     lty=0, tick=NA, las=3, line=6)\ntitle(\"House Prices in Canton NY\")\n\n\n\n\nOr if you wish to do the rainbow many group boxplot at the beginning, the code is here : https://github.com/fawda123/diss_proc/blob/master/diss_plot.R\n \n\n\n\n\nViolin plots combine the simplicity of a boxplot with a sense of the underlying distribution. This is useful when you want a sense of both the symmetry of the data and the underlying distribution. Highly recommended! For a single variable, consider a box-plot-with-histogram (see below).\nThere are MANY on R graph gallery with code you can copy/edit: https://www.r-graph-gallery.com/violin.html\nFor example, for our data:\n\n# fill=name allow to automatically dedicate a color for each group\nggplot(HousesNY, aes(x=Beds, y=Price, fill=Beds)) + \n   geom_violin()\n\nWarning: Groups with fewer than two data points have been dropped.\n\n\n\n\n\nThere’s also a beautiful package called ggstatsplot which allows a lot of detail (https://indrajeetpatil.github.io/ggstatsplot/)\nFor example, I love the plot below because it shows how much data in each group.\n\n# you might need to first install this.\nlibrary(ggstatsplot)\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\n# i'm changing the middle mean point to be dark blue\n\nggbetweenstats(data = HousesNY,x = Beds,y = Price, \n               centrality.point.args=list(color = \"darkblue\"))\n\nWarning: Groups with fewer than two data points have been dropped.\n\n\n\n\n\nOr we can customise it even more using this tutorial to get results like this (https://www.r-graph-gallery.com/web-violinplot-with-ggstatsplot.html)\n \n\n\n\nEspecially just looking at a single response variable, it’s useful to look immediately at the distribution itself. Histograms are great for this, although you must be careful that the bin size doesn’t impact your perception of results. Adding in a boxplot is often useful\nHere is the absolute basic histogram\n\nhist(HousesNY$Price)\n\n\n\n\nOr changing the bin size\n\nhist(HousesNY$Price,br=40)\n\n\n\n\nIn GGPlot 2, it’s also easy\n\nggplot(data=HousesNY, aes(x=Price)) + \n  geom_histogram(bins=20) \n\n\n\n\nOften, a boxplot AND a histogram is useful as it allows you to see a sense of the data shape and its underlying symmetry. For example, in base R\n\n# Layout to split the screen\ngraphics::layout(matrix(c(1,2),2,1, byrow=TRUE),  \n       height = c(2,7))\n \n# Draw the boxplot and the histogram \npar(mar=c(0, 3.1, .5, 2.1))\n\ndata_to_plot <- HousesNY$Price\n\nrangeplot <- pretty(data_to_plot,10)\n\nboxplot(data_to_plot,col = \"light blue\",\n        border = \"dark blue\",xaxt=\"n\",frame=FALSE,xlim=c(0.75,1.25),\n        horizontal = TRUE,notch = TRUE,ylim=c(min(rangeplot),max(rangeplot)))\n\npar(mar=c(3, 3.1, .5, 2.1))\nhist(data_to_plot , breaks=20 , \n     col=grey(0.3) , border=F , \n     tcl=-.25,mgp=c(1.75,.5,0),\n     main=\"\" , xlab=\"Price of houses in Canton NY\", \n     xlim=c(min(rangeplot),max(rangeplot)))\nbox();grid();\nhist(data_to_plot , breaks=20 , add=TRUE,\n     col=grey(0.3) , border=F , axis=FALSE,\n     xlim=c(min(rangeplot),max(rangeplot)))\n\n\n\n\nAnd the same with ggplot2:\n\nlibrary(ggExtra)\n\np <- ggplot(data=HousesNY, aes(x=Price)) + \n  geom_point(aes(y = 0.01), alpha = 0) +\n  geom_histogram(bins=20) +\n  geom_density(na.rm=T)\n\nggMarginal(p, type=\"boxplot\", margins = \"x\")\n\nWarning: Continuous x aesthetic\nℹ did you forget `aes(group = ...)`?\n\n\n\n\n\nI also love the ggstatplot version\n\nlibrary(ggstatsplot)\n## plot\ngghistostats(\n  data       = HousesNY, ## dataframe from which variable is to be taken\n  x          = Price, ## numeric variable whose distribution is of interest\n  title      = \"Price of sampled houses in Canton NY\", ## title for the plot\n  caption    = \"Source: Zillow\",\n  type = \"parametric\",\n  xlab = NULL,subtitle=FALSE,\n  ggthemes::theme_tufte(),\n  binwidth   = 8) ## binwidth value (experiment)\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\nℹ The deprecated feature was likely used in the ggstatsplot package.\n  Please report the issue at\n  <\u001b]8;;https://github.com/IndrajeetPatil/ggstatsplot/issues\u0007https://github.com/IndrajeetPatil/ggstatsplot/issues\u001b]8;;\u0007>.\n\n\n\n\n\nOr their version that includes a lot of associated statistics. You can turn many of these on and off\n\nlibrary(ggstatsplot)\n\n## plot\ngghistostats(\n  data       = HousesNY, ## dataframe from which variable is to be taken\n  x          = Price, ## numeric variable whose distribution is of interest\n  title      = \"Price of sampled houses in Canton NY\", ## title for the plot\n  caption    = \"Source: Zillow\",\n  type = \"parametric\",\n  xlab = NULL,\n  ggthemes::theme_tufte(),\n  binwidth   = 8) ## binwidth value (experiment)\n\n\n\n\n\n\nSometimes seeing a smoothed line helps draw the eye to distributions\n\nhist(HousesNY$Price, prob = TRUE,\n     main = \"Canton Prices with density curve\")\nlines(density(HousesNY$Price), col = 4, lwd = 2)\nbox()\n\n\n\n\n\n\n\nLet’s say you want to make plots similar to the ones in the lectures where there is your chosen distribution on top.\nIf you know the distribution, you can simply add it on top as a line\n\nmysample <- HousesNY$Price\n\nplotmin <- mean(mysample) - sd(mysample)*3\nplotmax <-  mean(mysample) + sd(mysample)*3\n\n# Points for the normal equation line\nNormCurve_x <- seq(plotmin,plotmax, length = 40)\n\n# Normal curve calculation for each point\nNormCurve_y <- dnorm(NormCurve_x, mean = mean(mysample), sd = sd(mysample))\n\n# make sure this is density not raw frequency\nhist(mysample , breaks=20 , freq=FALSE,\n     col=grey(0.5) , border=F , \n     xlim=c(plotmin,plotmax),\n     tcl=-.25,mgp=c(1.75,.5,0),\n     main=\"\" , xlab=\"Price of houses in Canton NY\")\n# add the normal curve (THIS NEEDS TO BE IN THE SAME CODE CHUNK)\nlines(NormCurve_x, NormCurve_y, col = 2, lwd = 2)\nbox()\n\n\n\n\nWe could plot any old curve this way, it doesn’t have to be “fit” to our data. For example here is a random gamma function\n\nmysample <- HousesNY$Price\n\n# Points for the normal equation line\nGammaCurve_x <- seq(plotmin,plotmax, length = 60)\nGammaCurve_y <- dgamma(GammaCurve_x,shape = 2)\n\n# make sure this is density not raw frequency\nhist(mysample , breaks=20 , freq=FALSE,\n     col=grey(0.5) , border=F , \n     xlim=c(plotmin,plotmax),\n     tcl=-.25,mgp=c(1.75,.5,0),\n     main=\"\" , xlab=\"Price of houses in Canton NY\")\n# add the normal curve (THIS NEEDS TO BE IN THE SAME CODE CHUNK)\nlines(GammaCurve_x, GammaCurve_y, col = 2, lwd = 2)\nbox()\n\n\n\n\n\n\n\nOr you can easily compare two datasets, tutorial for this plot here: https://www.r-graph-gallery.com/histogram_several_group.html\n \n\n\n\n\nThese are another way of looking at histograms for different groups. They work especially when your grouping data is ORDINAL (has some inherent order). So bedrooms would be a good example\nTwo great pages here:\n\nhttps://www.data-to-viz.com/graph/ridgeline.html\nhttps://r-charts.com/distribution/ggridges/\n\nWe can use histograms or smoothed density lines https://www.data-to-viz.com/graph/ridgeline.html\n\nlibrary(ggridges)\nlibrary(ggplot2)\n\nHousesNY %>%\n  ggplot( aes(y=Beds, x=Price,  fill=Beds)) +\n    geom_density_ridges(alpha=0.6, stat=\"binline\") +\n    scale_fill_viridis(discrete=TRUE) +\n    scale_color_viridis(discrete=TRUE) +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      panel.spacing = unit(0.1, \"lines\"),\n      strip.text.x = element_text(size = 8)\n    ) +\n    xlab(\"\") +\n    ylab(\"Number of Bedrooms\")\n\n`stat_binline()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAll of these are from https://r-charts.com/distribution/ggridges/\n\nlibrary(ggridges)\nlibrary(ggplot2)\n\nggplot(HousesNY, aes(x = Price, y = Beds, fill = stat(x))) +\n  geom_density_ridges_gradient() +\n  scale_fill_viridis_c(name = \"Depth\", option = \"C\") +\n  coord_cartesian(clip = \"off\") + # To avoid cut off\n  theme_minimal()\n\nWarning: `stat(x)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(x)` instead.\n\n\n\n\n\nWe can also make the colours more meaningful, for example adding quantiles to show the median and interquartile range\n\nggplot(HousesNY, aes(x = Price, y = Beds, fill = stat(quantile))) +\n  stat_density_ridges(quantile_lines = FALSE,\n                      calc_ecdf = TRUE,\n                      geom = \"density_ridges_gradient\") +\n  scale_fill_brewer(name = \"\")\n\nPicking joint bandwidth of 16.8\n\n\n\n\n\nor highlighting tails\n\nggplot(HousesNY, aes(x = Price, y = Beds, fill = stat(quantile))) +\n  stat_density_ridges(quantile_lines = TRUE,\n                      calc_ecdf = TRUE,\n                      geom = \"density_ridges_gradient\",\n                      quantiles = c(0.05, 0.95)) +\n  scale_fill_manual(name = \"Proportion\", \n                    values = c(\"#E2FFF2\", \"white\", \"#B0E0E6\"),\n                    labels = c(\"(0, 5%]\", \"(5%, 95%]\", \"(95%, 1]\"))\n\nPicking joint bandwidth of 16.8\n\n\nWarning: Using the `size` aesthietic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\n\nThese are cool. As described here:\nhttps://www.rhoworld.com/i-swarm-you-swarm-we-all-swarm-for-beeswarm-plots-0/#:~:text=What%20is%20a%20beeswarm%20plot%3F&text=A%20beeswarm%20plot%20improves%20upon,bees%20buzzing%20about%20their%20hive.\n“But what is a beeswarm plot? … A beeswarm plot improves upon the random jittering approach to move data points the minimum distance away from one another to avoid overlays. The result is a plot where you can see each distinct data point, like so: It looks a bit like a friendly swarm of bees buzzing about their hive.”\nIt’s often used for professional visualisation, see here for many examples: https://flowingdata.com/charttype/beeswarm\nEspecially for the first, you can see the distribution clearly, also with the amount of data. With the second, you can see the mitigating impact of a second variable.\nTo make easy ones you can install a new packages “beeswarm”\n\nlibrary(\"beeswarm\")\n\nbeeswarm(HousesNY$Price,\n         vertical = FALSE, method = \"hex\")\n\n\n\n\nThis is a little boring for my 58 data points! (although perhaps it does show that 58 points is barely a big enough sample to know an underlying model..)\n \n\n\n\nHere is the absolute basic scatterplot\n\n# you can either do plot(x, y)\n# OR (recommended), use the ~ to say plot(y~x) \n# e.g. y depends on x\nHousesNY$Beds <- as.numeric(HousesNY$Beds)\n\nplot(HousesNY$Price ~ HousesNY$Beds)\n\n\n\n\nThere are many things we can change, see the help file for the par command for more.\nFor example, here is an ugly plot showing as many as I can think!\n\nplot(HousesNY$Price ~ HousesNY$Beds,\n     xlim=c(0,7), #xlimits\n     ylim=c(40,220), #ylimits\n     xlab=list(\"Beds\",cex=.8,col=\"red\",font=2), # play with x-label\n     ylab=list(\"Price\",cex=1.2,col=\"blue\",font=3), # play with x-label\n     main=\"Ugly feature plot\",\n     cex=1.2, #point size\n     pch=16, # symbol shape (try plot(1:24,1:24,pch=1:24 to see them all))\n     tcl=-.25, # smaller tick marks\n     mgp=c(1.75,.5,0)) # move the x/y labels around\n\ngrid() #  add a grid\n\n# lines means \"add points on top\"\nlines(HousesNY$Price ~ HousesNY$Beds, \n     type=\"p\", # p for points, \"l\" for lines, \"o\" for both, \"h for bars\n     xlim=c(0,7), #xlimits\n     ylim=c(40,220), #ylimits\n     col=\"yellow\",\n     cex=.5, #point size\n     pch=4) # move the x/y labels around\n\n\n\n\nTo add a line, you can use the abline command IN THE SAME CODE CHUNK. For example\n\nplot(HousesNY$Price ~ HousesNY$Beds,\n     xlim=c(0,7), #xlimits\n     ylim=c(40,220), #ylimits\n     xlab=list(\"Beds\",cex=.8,col=\"red\",font=2), # play with x-label\n     ylab=list(\"Price\",cex=1.2,col=\"blue\",font=3), # play with x-label\n     main=\"\", # no title\n     cex=1.2, #point size\n     pch=16, # symbol shape (try plot(1:24,1:24,pch=1:24 to see them all))\n     tcl=-.25, # smaller tick marks\n     mgp=c(1.75,.5,0)) # move the x/y labels around\n\n# add vertical line at 3.5\nabline(v=5.5,col=\"red\")\n# add horizontal line at the mean of price\nabline(h=mean(HousesNY$Price)) \n# add line of best fit\nabline(lm(HousesNY$Price ~ HousesNY$Beds),col=\"blue\",lty=\"dotted\",lwd=3) \n\n\n\n\nGGPlot also has basic and advanced options. From the basics:\n\nlibrary(ggplot2)\n#\nggplot(HousesNY, aes(x=Beds, y=Price)) + \n    geom_point()\n\n\n\n\nTo more advanced:\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\n\n# use options!\nggplot(HousesNY, aes(x=Beds, y=Price)) + \n    geom_point(\n        color=\"black\",\n        fill=\"#69b3a2\",\n        shape=22,\n        alpha=0.5,\n        size=6,\n        stroke = 1\n        ) +\n    theme_ipsum()\n\n\n\n\nAdding a line of best fit is also easy, but fits less easily with R’s modelling commands:\n\n# Library\nlibrary(ggplot2)\nlibrary(hrbrthemes)\n\n# Create dummy data\ndata <- data.frame(\n  cond = rep(c(\"condition_1\", \"condition_2\"), each=10), \n  my_x = 1:100 + rnorm(100,sd=9), \n  my_y = 1:100 + rnorm(100,sd=16) \n)\n\n# Basic scatter plot.\np1 <- ggplot(data, aes(x=my_x, y=my_y)) + \n  geom_point( color=\"#69b3a2\") +\n  theme_ipsum()\n \n# with linear trend\np2 <- ggplot(data, aes(x=my_x, y=my_y)) +\n  geom_point() +\n  geom_smooth(method=lm , color=\"red\", se=FALSE) +\n  theme_ipsum()\n\n# linear trend + confidence interval\np3 <- ggplot(data, aes(x=my_x, y=my_y)) +\n  geom_point() +\n  geom_smooth(method=lm , color=\"red\", fill=\"#69b3a2\", se=TRUE) +\n  theme_ipsum()\n\np1\n\n\n\np2\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\np3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nOr using the plotly library to make your plots interactive (really useful, try zooming in or clicking on a few points)\n\n# create the plot, save it as \"p\" rather than print immediately\nmyplot <-   ggplot(HousesNY, aes(x=Beds, y=Price, label=Baths)) + \n            geom_point(alpha=.5) +\n            theme_classic()\n            \n# and plot interactively\nggplotly(myplot)\n\n\n\n\n\nIt’s also very easy to add in color to see another variable. For example\n\n# create the plot, save it as \"p\" rather than print immediately\nmyplot <-   ggplot(HousesNY, aes(x=Beds, y=Price,color=Baths)) + \n            geom_point(alpha=.5) +\n            theme_classic()+\n            scale_color_gradient(low=\"blue\", high=\"red\")\n\n# and plot interactively\nggplotly(myplot)\n\n\n\n\n\nMany more interactive options in this tutorial: https://plotly.com/r/line-and-scatter/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "in_S462_Lab1.html",
    "href": "in_S462_Lab1.html",
    "title": "Lab 1: R intro",
    "section": "",
    "text": "The aim of this lab is to get comfortable in R and in R-Markdown, and to practice identifying some study jargon as we practiced in class. Lab instructions will be here and how-tos will be condensed into the Tutorial\nThe Canvas page for this lab is: https://psu.instructure.com/courses/2243429/assignments/14748231\nIf the labs are causing major problems with your computer or your computer hardware is struggling (or you have any other software issue), Talk to Dr Greatrex.\nWe can fix this and there are other options for “online R” that you can use.\n\n\n\n\nFirst, please review the lab Q&A: CLICK HERE. It explains\n\nWhat you need to submit\nHow you are graded and where the rubric is\nThe late policy\nWhat counts as cheating\n\n\n\n\nReview CLICK HERE to see some of the powerful things we can do in R.\nWe will do this in class.\nYour homework:\n\n\n\n\nCreate a new RMarkdown document called STAT462-Lab1-PSUID.Rmd. e.g. for me STAT462-Lab1-hlg5155.Rmd. \nDelete any friendly welcome text so you have a blank space.\n\n\n\nYou might find it easier to use the markdown visual text editor.  Click the “Visual” symbol at the top left of the document to switch.\n\nIn the white text area, create a level 1 Header called “Introduction to STAT-462”.\nLeave a blank line, then use the STAT-462 syllabus to describe the course late policy in your own words (e.g. you’re writing about this in the white space).\nPress “knit” at the top of the screen. If you haven’t made a mistake a pop up should appear with a html file and your edits. If you have a made a mistake, stop and fix before continuing or talk to a teacher.\n\n\n\n\n\n\n\n\n\n\n\n<br<\nLeave another blank line and add a new Level 1 Header called “Code Showcase”. Add a blank line afterwards too - the reason for all the blank lines is that R formatting often gets messed up with not enough blank lines, but it will ignore excess ones.\nCreate a code chunk. Inside use R code to calculate the following. You HAVE to show the code! \n\n1033 (e.g 103*103*103, or 103^3) \n\n_ The co-sine of your age (google is your friend, google R function for cosine) \n\nUse R code to work out how many characters are in the longest town name in Wales Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch. \n\n\nHint 1, remember you can copy paste this into your code. \nHint 2.. your tutorials and quote marks!\nHint 3.. you can google any R command, try googling the “R command for number of characters in a word”.\n\n\nPress “knit” at the top of the screen. If you haven’t made a mistake a pop up should appear with a html file and your edits. If you have a made a mistake, stop and fix before continuing.\n\n\n\n\nToday we will be using commands from several packages. Somewhere near the top of your script, make a new code chunk and add this code. We will probably have to install them first (see the tutorial)\nRemember to run the code chunk! (pressing the green arrow, or go to the run button on the top right and press Run All)\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(ggpubr)\nlibrary(palmerpenguins)\n\n\n\n\n\n\n\nLeave a blank line, and create a new level 1 heading called Penguin Analysis. Leave a blank line afterwards too. We’re going to work with a table of data that’s already pre-loaded into R inside the ggplot2 package.\n\nMake sure you have run the library code chunk above without error, or it won’t work. \nLoad the data using this command. You can ignore the raw penguin data\n\n\ndata(\"penguins\")\n\n\n\nType the ?penguins command in the console. This will bring up the help file.\nState the\n\n\nObject of Analysis\nA reasonable population you would be happy to apply this dataset to*\nVariables and units - you are allowed to copy these names/units from the help file\n\n*Imagine you are giving this analysis to a newspaper editor. What population do you think this sample could represent?\n\n\n\n\nNow look at the data itself. If you look in the environment tab, you will see a new variable called penguins Click on it’s NAME to see the spreadsheet/table itself and familiarise yourself with the data.  \nWe could have also looked at the data by either by typing its name into the console, the command View(penguins) or a code chunk, or by using commands like head(penguins) to show the first few lines\n\n\n\nLet’s look at the summary statistics. Leave a blank line and create a new code chunk containing the following code \n\n# mpg comes from the ggplot2 package\n# skim comes from the skimr package\nskim(penguins)\n\nThis command compiles the summary statistics for the penguin dataset - sometimes its easier to view this if you press the knit button and look at the html pop-up. You can also use the summary() command to achieve a similar result \n\nsummary(penguins)\n\nSummarise the dataset.\nThis should include:\n\nA short description of any missing data. For example, are there entire rows missing? Certain columns? Imagine you are using this dataset for modelling, are there rows that will need removing? etc etc? Try `View(penguins)` to look at the penguin dataset itself\n\nHow many penguins were from 2008?\n\nHint, the table command..\nHint 2, to choose a column use the $ sign e.g. tablename$columnname\nHint 3, R IS CASE SENSITIVE!\n\n\nA histogram of one variable of your choice and a description of the variable.\nE.g. unimodal? skewed? Any outliers?\n\n*Hint https://allisonhorst.github.io/palmerpenguins/articles/examples.html *\n\n\nA scatterplot between two variables of your choice and a description of the scatterplot\n\nHint https://allisonhorst.github.io/palmerpenguins/articles/examples.html *\n*Hint 2, for a description, see this Khan page\n\n\nThe correlation between two variables of your choice\n\nHint, the cor command *\n\n\nA correlation test fully written up in a way that a non expert would understand. For example you include the H0,the H1 the test statistic, the p value and your interpretation. I will let you choose your own significance threshold. You should also show the code output.\n\n*Hint, the cor.test command and see the Canvas correlation page for interpretations.\n\n\n\n*In step 3 and 4 you are allowed to copy the code. There are two reasons for this. The first is that many of you are new to R, it’s lab 1 and I want you to get more exposure to what R looks like (and this is how I learn new coding techniques). The second is that we can spend weeks learning how to make a basic histogram, but now there are all of these amazing professional plots that can be made with a little more code, so I would prefer you spent your time learning them :)\n\n\n\n\nRemember to save your work throughout and to spell check your writing (next to the save button). Now, press the knit button again. If you have not made any mistakes in the code then R should create a html file in your lab 1 folder which includes your answers. If you look at your lab 1 folder, you should see this there - complete with a very recent time-stamp.\nIn that folder, double click on the html file. This will open it in your web-browser.\nCHECK THAT THIS IS WHAT YOU WANT TO SUBMIT.\nIf you are on R studio cloud, see Tutorial 1 for how to download your files\nNow go to Canvas and submit BOTH your html and your .Rmd file in Lab 1."
  },
  {
    "objectID": "in_S462_Lab2.html",
    "href": "in_S462_Lab2.html",
    "title": "Lab 2: Scatterplots",
    "section": "",
    "text": "The aim of this lab is to continue to get comfortable in R and to practice the mix of word processing and report editing\nThe Canvas page for this lab is: https://psu.instructure.com/courses/2243429/assignments/14748231\nIf the labs are causing major problems with your computer or your computer hardware is struggling (or you have any other software issue), Talk to Dr Greatrex and REMEMBER YOU CAN ALWAYS USE RSTUDIO CLOUD.\n\n\n\n\n\nFirst, please review the lab Q&A: CLICK HERE. It explains\n\nWhat you need to submit\nHow you are graded and where the rubric is\nThe late policy\nWhat counts as cheating\n\n\n\n\nIMPORTANT! The tutorials are MUCH BETTER - follow and work through Tutorial 2.\nYou should now have a new project and a new RMarkdown file that knits.\nCreate a code chunk near the top and load these packages. You may need to install them first using tutorial 2.\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggpubr)\nlibrary(skimr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(ISLR)\nlibrary(equatiomatic)\nlibrary(olsrr)\nlibrary(Stat2Data)\nlibrary(readxl)\nlibrary(tmap)\n\n\n\n\n\n\n\nAs well as code, I also want you to be able to embed images or videos into your report.\nQ1: Follow Tutorial 4b to add images to add an image or video of your choice into your report. (note, non-english characters in file names or huge photos will break R)\nQ2. Use a bullet point list (see tutorial 2 visual mode or google) to explain why you chose those photos/images.\n\n\n\nFinally, to make your code look neat, we can edit the “YAML” code at the top. Look at Tutorial 3B - and add a title, author, today’s date (copy/paste the command) and a table of contents if your template does not have one already and allows it.\n\n\n\n\nTHIS USED TO BE IN LAB 3 - Ignore any lab 3 references\nCreate a new Level 1 heading called House Prices.\nNext month, your friend is moving to Sindian Dist., in New Taipei City, Taiwan. They want to buy a house and have asked you to figure out what most impacts house price.\n\nDownload the “Lab03_house.xlsx” dataset from the Lab page on canvas and put it into your Lab 2 folder. Use the read_excel() command to read it in and save it to a variable called house:\n\n\n# This only works if you are running your project\n# If it can't find the file, use file.choose() to locate it,\n# Then add in the full location rather than just the file name.\nhouse <- read_excel(\"Lab03_house.xlsx\")\n\n\nExplore the dataset (using summaries etc, and by reading more about the data here: https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set). Describe the dataset to your friend. What columns does the dataset contains and how much data there is? Are there any limitations using this data?\n\nIMPORTANT - WHAT ARE THE UNITS OF THE VARIABLES? WHAT IS THE OBJECT OF ANALYSIS? (Remember to write these in your summary)\n\nUse R to explore the summary statistics and distribution of the House.Price column. What range of costs are “most” of the prices between? (say 68% or the interquartile range..) Is the house price data normally distributed? See the distributions tutorial\nYou have a been told that houses might be more expensive in the North.\n_ Choose your response and your predictor\n\nCreate a scatterplot to assess this (hint: Latitude is the North/South coordinate).\nDescribe the scatterplot and describe it as in lectures\nCreate a Simple Linear Regression model to assess the issue - See this Tutorial\nPlot the abline, line of best fit onto a new scatterplot\n\nWhy might this be misleading as an analysis? or why might this model be flawed? What confounding variable could there be? To help you answer this question, try running this code to further explore the data on a map.\nYou might have to first install the sf package and add library(sf) to your library code chunk (and re-run)\n\n\n# Command from the sf library\n# Make a spatial version of the data using the Longitide and Latitude columns\nhouse.spatial <- st_as_sf(house,coords=c(\"Longitude\",\"Latitude\"),crs = 4326)\n\n# make interactive, for static set as \"plot\"\ntmap_mode(\"view\")\n\n\n# Command from the tmap library\n# and plot\ntm_basemap(\"Esri.WorldTopoMap\") + \n     qtm(house.spatial, # data\n         symbols.col=\"House.Price\", # which column for the symbols\n         symbols.alpha=0.9, # transparency\n         symbols.size=.2, # how big\n         symbols.palette=\"Spectral\", #colors from https://colorbrewer2.org\n         symbols.style=\"fisher\") # color breaks\n\n\nWhat other confounding variables are there? Is there a variable that is more important than latitude in predicting house prices? Provide evidence to justify your answer. To help you answer this data and answer this question, some useful code includes:\n\n\n[A] corrplot(). A quick look at the correlation coefficient between all the variables. We will discuss it more next week.\n\n\ncorrplot(cor(house),method=\"number\",type=\"lower\")\n\n\n[B] If you then want to look at three variables together, you can use an interactive plot e.g you can use this code and change the response, y (currently house price), the predictor x (currently latitude) and the colour (currently distance from the metro station). Have a play and see what variables stand out.\n\n\n# Create a plot\np <- house %>%                  \n  ggplot( aes(Latitude,House.Price, col= House.Age)) +\n  geom_point() +\n  theme_classic()+\n  scale_color_gradient(low=\"blue\", high=\"red\")\n\n# and actually plot it\nggplotly(p)\n\n\nYou can also use standard scatterplots and regression models if that is easier. Or even excel and screenshots embedded in your report if it is all going wrong!\n\n\nYour friend forgot to tell you that they love shopping. They only want to live in a house that is close to at least 7 shops, but are worried that they might end up paying too much.\n\nFilter the data so that it only includes 7 or more nearby shops e.g you’re subsetting by the number of shops column (Tutorial 2C, section 1.8.6). Save the output to a new variable called house.gt7shop.\n\nRun a t.test to find out if your house.gt7shop data has a mean that is significantly higher than the mean of the house prices over the whole region (Tutorial 2D, 1.9.2). Remember to write up your hypotheses, the results and the conclusion in plain English that your friend would understand.\n\n[OPTIONAL BONUS 2%] How much does the house price go up for every 1 KILOMETER that you travel away from a metro station? Hint(remember the lm command..)\n\n\n\n\nRemember to save your work throughout and to spell check your writing (next to the save button). Now, press the knit button again. If you have not made any mistakes in the code then R should create a html file in your lab 1 folder which includes your answers. If you look at your lab 1 folder, you should see this there - complete with a very recent time-stamp.\nIn that folder, double click on the html file. This will open it in your web-browser.\nCHECK THAT THIS IS WHAT YOU WANT TO SUBMIT.\nIf you are on R studio cloud, see Tutorial 1 for how to download your files\nNow go to Canvas and submit BOTH your html and your .Rmd file in Lab 1."
  },
  {
    "objectID": "in_S462_Tutorial1WhatisR.html",
    "href": "in_S462_Tutorial1WhatisR.html",
    "title": "T1: R Basics",
    "section": "",
    "text": "Watch this 1 minute video on R-Studio: https://www.rstudio.com/products/rstudio/\nOr, if you prefer, this 5 minute video\n\n\n\n\n\n\n\n\n\n\n\n\nR is a free, open source statistical programming language. It contains millions of commands that are useful for data cleaning, analysis, and visualization.\nBy a “programming language”, I mean it is a collection of commands that you can type into the computer in order to analyse and visualise data.\nThe easiest way I find to think about R is that it is literally a language, like Spanish or Hindi, that is spoken by your computer. Learning R means learning vocabulary and grammar in order to communicate. It also means it will get easier with experience and practice..\n\n\n\nR-studio is a software environment, e.g a programmed designed to make it easy to write code in the language R.\nIt has many useful features. For example, you can easily see help files, run code, see your output and create outputs like this lab book! R-Studio also allows us to make interactive documents called R-Markdown files.\n\n\n\n\n\nR-studio is much more sophisticated"
  },
  {
    "objectID": "in_S462_Tutorial1WhatisR.html#using-r-studio-cloud",
    "href": "in_S462_Tutorial1WhatisR.html#using-r-studio-cloud",
    "title": "T1: R Basics",
    "section": "Using R Studio Cloud",
    "text": "Using R Studio Cloud\nThe easiest way to get R-studio is to use the R-Studio Cloud website\nThis is an online version of R-Studio. and I believe it’s free for the first 25hrs each month. If you need more time, you can make a new account, or pay for one month, or move to your desktop.\n\nAdvantages:\n\nIt’s always up to date\nSuper Easy. You will never have to worry about versions or updating.\nProjects are incredibly easy and I can debug things fast\nYou can do your labs anywhere you have access to a webpage \n\nDisadvantages:\n\nIt’s not as powerful, you won’t be able to play will millions of data points\nYou have to be online; bad internet connections make it harder\n\n\nTo sign up, make an account at https://rstudio.cloud/plans/free, then click the tabs here to look around. Sadly there is no student pricing right now.\n\n\nBefore each lab, making a project\nOnce you have logged in, you will get to a dashboard like this, called the R-studio workspace. You make a new project by clicking the button on the top right. You can open different projects in different tabs on your browser. You can also go back to the work-space at any time.\nYou can get here from any web-browser, You do not need a special computer.\nYOU SHOULD MAKE A NEW PROJECT FOR EACH LAB.\n\n\n\n\n\nThe Cloud dashboard\n\n\n\n\n\n\nReturning to your lab project\nOn the cloud this is very easy, just go back to https://rstudio.cloud/content/yours\n\n\nDownloading files\nYou will need to submit two files for each lab, an “.Rmd” and a “.html”. More later on those, but here is how to download them from the cloud so you can submit them\n\nOn the R-Studio Cloud website; inside your project, go to the files tab (next to Projects/Help in one quadrant. You will see a list of files, one with the file type .Rmd (your code) and one with .html(the website you made when you pressed knit). Look at the red circle in the pic below\nClick the check-box to the left of the .RmD file\nLook just above at the Files quadrant settings menu. Click the blue “more” cogwheel icon. (see diagram). You might need to make R-Studio full screen to see it.\nNow click export. This will download the file\nREPEAT FOR THE HTML (you can do them together but it exports as a zip)\nSubmit both files on Canvas\n\n\n\n\n\n\nDownloading the files\n\n\n\n\n\n\nUploading files\nSometimes you want to put your code into R-Studio Cloud, for example if for one week you don’t want to bring your laptop.\nMake a project for the lab, then click the upload button inside your project in the files tab and upload your files. You will only need the .RmD file and any data files. You do not need the html etc (as you create that when you press knit)\n\n\n\n\n\nLook near the red circles"
  },
  {
    "objectID": "in_S462_Tutorial1WhatisR.html#using-r-on-your-laptopdesktop",
    "href": "in_S462_Tutorial1WhatisR.html#using-r-on-your-laptopdesktop",
    "title": "T1: R Basics",
    "section": "Using R on your Laptop/Desktop",
    "text": "Using R on your Laptop/Desktop\nIf you have your own computer, you can run R and R-Studio for free on there.\n\nAdvantages:\n\nIts powerful and we will learn how to use and update it\nNo need for the internet\nYou can play with millions of data points \n\nDisadvantages:\n\nIt can be annoying to install and update, especially on old computers.\nYou are tied to your laptop/computer (although you can uplaod your files to the cloud)\n\n\n\nThe VERSION of R you use is important!\nIf you already have R and/or R-Studio, it is very important you update BOTH of them to the most recent version. To do so, pretend you are installing them from scratch. If you are worried this will affect another class, chat with Dr Greatrex before starting out.\nWhy is this so important? Just as English has evolved over the years, the R language is always evolving. We keep track using Versions.\nTo make sure we are all on the same page, you need the most up-to-date version of the R commands.\nThe version of R I am using is :\n\n\n[1] \"R version 4.2.2 (2022-10-31) Innocent and Trusting\"\n\n\nAs long as yours is that or above that you should be fine. The current most recent version of the language on the website is:\n\n\n[1] \"The latest release (2022-10-31, Innocent and Trusting)\"\n\n\n\n\nInstalling/updating R.\nTo make R-Studio run on your computer, you need to download TWO things:\n\nR: The thing that teaches your computer the ability to “speak” in R\n\nThe R studio software itself\n\n\nOn a PC:\n\n[STEP 1 of 2] Download & install the R-language itself:\n\nGo to: https://cloud.r-project.org/bin/windows/base/ ,\nDownload this version of R (the main download R for windows button)\n\n\n\n\n[1] \"The latest release (2022-10-31, Innocent and Trusting)\"\n\n\n-   Run and click next through all the options\n\n[STEP 2 of 2] Download & install R studio:\n\nGo to: https://www.rstudio.com/products/rstudio/download/#download> ,\ndownload R studio for windows\nRun and click next through all the options\n\n\n\n\n\nOn a Mac:\n\n[STEP 1 of 2] Download & install the R-language itself for mac:\n\nGo to:https://cloud.r-project.org/bin/macosx/ ,\ndownload this version of R (the .pkg file on the left menu)\n\n\n\n[1] \"The latest release (2022-10-31, Innocent and Trusting)\"\n\n\n\nRun and click next through all the options\n\n[STEP 2 of 2] Download & install R studio for mac:\n\nGo to: https://www.rstudio.com/products/rstudio/download/#download> ,\ndownload R studio for Mac\nRun and click next through all the options\n\n\n\n\n\nBefore each lab, making a project\n\nIMPORTANT! If you haven’t already, on an easy to access place on your computer, make a folder called STAT-462. This is where ALL your labs are going to live.\nNow everything is installed, open R-studio (NOT R!).\n\n\n\n\n\n\n\n\n\n\n\nGo to the file menu at the very top and click New Project\nSelect New Directory, then New Project\nName your project STAT462-Lab1-PROJECT (or whatever lab it us)\nUnder “create project as a subdirectory of”, hit the browse button and find your STAT-364 folder (you just need to be in the folder, you don’t need to have selected anything). Press open\nFinally, press Create Project\n\n\n\n\n\n\n\nHow to check you are in a project\nR will change slightly. If you look at the top of the screen in the title bar, it should say something like STAT462-Lab1-Project R Studio.\nThe Files tab should have gone to your project folder. Essentially, R-Studio is now “looking” inside your Lab 1 folder, making it easier to find your data and output your results.\n\n\n\n\n\nHow to check you are in a project, this one is for my last course\n\n\n\n\n\nEssentially, R-Studio is now “looking” inside your Lab 1 folder, making it easier to find your data and output your results.\nIf you want one, final check, try typing this into the console (INCLUDING THE EMPTY PARANTHESES/BRACKETS), press enter and see if it prints out the location of Lab 1 on your computer. If not, talk to an instructor.\n\ngetwd()\n\n\n\n\nReturning to your lab project\nOK, let’s imagine that you get halfway through your lab and your computer dies. How do you get back to your Lab work? Try this now. Close down R-Studio.\nTo reopen a lab:\n\nDO NOT RE-OPEN R-STUDIO!\nInstead navigate on your computer to your STAT-462/STAT462-Lab1-Project folder.\nDouble click on the STAT462-Lab1-Project.RProj file.\n\nThis will reopen R for that specific lab, so you can continue where you left off. It means you can also open several versions of R studio for multiple labs, which can be very useful in staying sane"
  },
  {
    "objectID": "in_S462_Tutorial1WhatisR.html#the-screen",
    "href": "in_S462_Tutorial1WhatisR.html#the-screen",
    "title": "T1: R Basics",
    "section": "The screen",
    "text": "The screen\nYou will be greeted by three panels:\n\nThe interactive R console (entire left)\nEnvironment/History (tabbed in upper right)\nFiles/Plots/Packages/Help/Viewer (tabbed in lower right)\n\n\n\n\n\n\n\n\n\n\nIf you wish to learn more about what these windows do, have a look at this resource, from the Pirates Guide to R: https://bookdown.org/ndphillips/YaRrr/the-four-rstudio-windows.html.\nIf you have used R before, you might see that there are variables and plots etc already loaded. It is always good to clear these before you start a new analysis. To do this, click the little broom symbol in your environment tab"
  },
  {
    "objectID": "in_S462_Tutorial1WhatisR.html#moving-the-4-quadrants-around",
    "href": "in_S462_Tutorial1WhatisR.html#moving-the-4-quadrants-around",
    "title": "T1: R Basics",
    "section": "Moving the 4 quadrants around",
    "text": "Moving the 4 quadrants around\nYou might find you like the different quadrants in a different order. To change this, look at the menu at VERY TOP OF THE SCREEN.\n\nIn theView menu, there is a /Panes/Pane Layout menu item, where you can move the on-screen quadrants around. I tend to like the console to be top left and scripts to be top right, with the plots and environment on the bottom - but this is personal choice.\n\n\n\n\n\n\nMy preferred set up\n\n\n\n\n\nThere should also be a menu called HelpUseful for R-studio version and Markdown cheatsheets."
  },
  {
    "objectID": "in_S462_Project2Setup.html",
    "href": "in_S462_Project2Setup.html",
    "title": "2. Causal Chains",
    "section": "",
    "text": "Overview\nSome of you will become future topic experts, for example rainfall or forest or finance specialists who get to design experiments and surveys. But many of you might become “general data scientists” so it’s important to be able to sensibly set up a study even on a topic you know little about with training data you didn’t get to collect.\nWith this in mind, I have chosen a topic I know a lot about and most of you are newer to, temperature measurements.\nYou need to have a “good rule of thumb” about what are confounding variables and what might be spurious correlations. Or whether you should worry about a strange result or accept it.\nTo do this we will be setting up our reports and making causal chain diagrams.\n\nStep 1. Introductions\n\nIntroduce yourselves and create a name for your group [5 mins]\nDecide (for today) who will take each of these four roles.\n\nYou will each be doing a mix of these things and you will get to switch in the future, but this will allow you to move forwards quickly.\n\n#Coordinator | Getting a project up and running, keeping track of everything. Whoever kept you on time for this first five minutes..\n#TopicExpert | Enjoy building statistical models & thinking about temperatures\n#VisualisationExpert/Words making things look good.\n#Modeller | Getting to grips with R & R Studio\n\nIf you do not have 4 members actively participating in your team, Dr G will take this into account.\n\n\n\n\nStep 2. Set up\nEach do this in parallel (15mins)\n\n#Modeller | We are going to be co-editing R-Studio cloud.\n\nGo to https://login.rstudio.cloud/ and log into posit cloud\nOn the top left, click NEW SPACE. If you are a heavy R studio cloud user, maybe nominate someone else so we can use their free allocation\nName the space STAT-462 Group: Name, where Name is the name of your group.\nGo to the members button at the top. Invite your group, plus hlg5155@psu.edu (me) as admin\nWork with the #coordinator to make sure everyone can access this and that there is a link on the teams page.\nIf you are done early, follow the topic expert instructions\n\n#Coordinator |\n\nGo to Canvas and click the temperature project new menu item. This will take you to Teams.\nYou can either use Teams via a web-browser or download it on your phone/computer.\nGo to your team’s space, and add the team name and each person with their role.\nWork with the #Modeller to make sure that everyone can access both Teams and R-Studio Cloud\nMake sure everyone can communicate with each other outside class.\nIf you are done early, follow the topic expert instructions\n\n#TopicExpert | Your job is to refresh your knowledge on temperature data\nexpand for more details\n\nGo here, https://psu.instructure.com/courses/2243429/discussion_topics/15168928 and start reading. Use this as a starting point to think about what might cause cold temperatures across town.\nGoogle things that look interesting, put relevant links/references/REFERENCED graphics in the teams chats\nIf the others join you, assign them a one or two sub-topics to look at or any questions you haven’t got to.\n\n#VisualisationExpert | Your job is to be prepared for the second half of the lab\n\nWe need to think hard about causation vs correlation, and spurious vs confounding variables.\nBriefly refresh your memory on what they are. This is a favourite site of mine, but there are many on google if this doesn’t work for you\nhttps://statisticsbyjim.com/regression/confounding-variables-bias/\n\n\n\n\nStep 3. Causal chain diagrams\nIn your report, you will need to include a causal diagram of what you EXPECT will impact temperature measurements across State College.\nFor example elevation doesn’t “cause” the number the thermometer reads to be different, there must be some steps in between...\nGiven this diagram and looking at a google map of the state college township area, where do you expect the coldest spot to be? And what will be the main predictors we can use to assess temperature\nDecide on the structure of your final diagram and how to present it in your report. You could make a beautiful hand drawn plot, a graphic using powerpoint, a jamboard https://jamboard.google.com/?pli=1 , something using R (no idea how to do that)\nSome good resources:\n\nhttps://iwlearn.net/manuals/tda-sap-methodology/development-of-the-tda/causal-chain-analysis/what-is-causal-chain-analysis\nhttps://www.juran.com/blog/the-ultimate-guide-to-cause-and-effect-diagrams/\nhttps://www.burgehugheswalsh.co.uk/Uploaded/1/Documents/Multiple-Cause-Diagram-Tool-Draft.pdf\nhttps://www.researchgate.net/figure/Themes-and-feedback-loops-in-the-synthesized-causal-loop-diagram-initiated-around-the_fig1_333100721\n\nThere are MANY ways you can approach this. The end goal is to convince Mr Northridge that you now know enough about temperatures that you can sensibly undertake the study. And to think hard about what to expect.\n\n\nStep 4. Write up\nA group report in RMarkdown. This should look good. Feel free to play with choosing a theme/template but don’t make it your whole life. Some ones I like are: https://github.com/juba/rmdformats and https://prettydoc.statr.me/themes.html - install instructions on the website.\nDescribe your assessment of the causes of spatial temperature change in State College at a level of detail suitable for me to the State College town council (lots of very clever people who know nothing about meteorology).\nNote, to include photos in Markdown see here https://poldham.github.io/minute_website/images.html - REMEMBER TO CITE/REFERENCE ANYTHING THAT’S NOT YOURS, formal citations encouraged, plagarism strictly banned)\nYou also need to include a causal loop diagram of what you EXPECT will impact temperature measurements across State College. Referring to this diagram and looking at a google map of the state college township area, where do you predict the coldest spot will be? And what will be the main predictors we should use to assess temperature?\nSubmission on Canvas\nHow is this graded?\n\nGiven the time delays on my side, generously!"
  },
  {
    "objectID": "in_S462_Tutorial0Index.html",
    "href": "in_S462_Tutorial0Index.html",
    "title": "Tutorial index",
    "section": "",
    "text": "Your tutorials\nWelcome to your tutorials. I have written all of these and will try and keep them up-to-date and not too overwhelming.\nKnow there is a search bar!\nIf you don’t find what you need here, see if you can find it on google or one of these useful sites:\n\nWonderful graphics with example code: https://r-graph-gallery.com/\nTidyverse tutorials & cheat sheets: https://www.tidyverse.org/learn/\nQuatro tutorials & cheat sheets: https://quarto.org/"
  },
  {
    "objectID": "in_S462_Lab0Index.html",
    "href": "in_S462_Lab0Index.html",
    "title": "Lab Q&A",
    "section": "",
    "text": "You will be creating two files; an Rmd file containing your code and a .html file for viewing your finished document.\nYou need to submit both of these files on the relevant Canvas assignment page. Remember you can also add comments to your submission as/if needed.\n\n\n\n\nThere are 70 points available. Remember you can drop your lowest lab (e.g. you can skip one)\nYou can see the SPECIFIC RUBRIC we use for this lab on the canvas page. It’s literally how we will award the marks.\nWe will also provide as much feedback as possible, so please remember to click the rubric button to take a look.\n\n\n\n\nOverall, here is what your lab should correspond to:\n\n\n\n\n \n  \n    POINTS \n    Approx grade \n    What it means \n  \n \n\n  \n    68-70 \n    A* \n    Exceptional.  Above and beyond.   THIS IS HARD TO GET. \n  \n  \n    65-68 \n    A \n    Everything asked for with high quality.   Class example \n  \n  \n    60-65 \n    B+/A- \n    Solid work but the odd  mistake or missing answer in either the code or interpretation \n  \n  \n    55-60 \n    B-/B \n    Starting to miss entire/questions sections, or multiple larger mistakes. Still a solid attempt.  \n  \n  \n    49-55 \n    C/C+ \n    It’s clear you tried and learned something.  Just attending labs will get you this much as we can help you get to this stage \n  \n  \n    40-49 \n    D \n    You submit a single word AND have reached out to Dr G or Aish for help before the deadline (make sure to comment you did this so we can check) \n  \n  \n    30-40 \n    F \n    You submit a single word…....  ANYTHING..                Think, that's 30-40 marks towards your total…. \n  \n  \n    0+ \n    F \n    Didn’t submit, or incredibly limited attempt.  \n  \n\n\n\n\n\n\n\n\n\nIf you have technical problems & have sent me canvas message with our code and a screenshot of the issue BEFORE THE DEADLINE, all late penalties go away until we have fixed it.\nSubmitting late is a risk. The lab might be graded at any time past the deadline with no notice given. If worked answers are released then that is too late.\nBut.. I would prefer you submit late than not at all. If you’re going to be late for any reason (you don’t need to explain why), send Dr G a canvas message.\nI will only start penalizing if you’re consistently late and I have sent a written warning. See the course syllabus for more info. https://psu.instructure.com/courses/2243429/assignments/syllabus\n\n\n\n\nYou can talk with each other to help during these labs e.g. you can see each others screens and work out answers together. I will try as much as possible to provide alternate datasets.\nBUT NEVER SHARE CODE/SEND SCRIPTS.\nALL TEXT SHOULD BE IN YOUR OWN WORDS.\nFor example:\n\nWorking out together the right way to apply the seq() function, then each independently adding it to your own scripts is OK.\nCopy/pasting your friend’s code/text is not..\nSo DISCUSS with friends, but then turn away to your own screen and write your own code and text.\n\nI will be randomly running lab reports through plagiarism software."
  },
  {
    "objectID": "in_S462_Project0Index.html",
    "href": "in_S462_Project0Index.html",
    "title": "Project Overview",
    "section": "",
    "text": "Overall goals\nSome of you will become future topic experts, for example rainfall or forest or finance specialists who get to design experiments and surveys. But many of you might become “general data scientists” so it’s important to be able to sensibly set up a study even on a topic you know little about with training data you didn’t get to collect.\nWith this in mind, I have chosen a topic I know a lot about and most of you are newer to, temperature measurements.\nDuring the semester we will be working on a group project of “messy data”. I have a strange request from Jere Northridge who is a State College town council Township Engineer. He would like to predict where in the state college township is the coldest place at Midnight on May-1. (for reasons..)\nI put out many temperature sensors to make a training dataset. You will be creating a series of regression models to see if you can understand it, then predict the location in College Township with the coldest temperature at midnight on the Monday May 1st.\n\nYour unit of analysis is a specific measurement from a mini sensor. E.g.. a measurement at location X on date/Time Y.\nYour spatial population of interest is State College Township\n\n\ninclude_graphics(\"./Figures/State College Township.png\")\n\n\n\n\n\nTo create our supervised model, I will provide as much training data as I can. This will be temperature sensor measurements from around the entire State College area. You will have to quality control this, add in meta data and create your models.\nWe will be writing up the following as a consultancy style professional report in R-Markdown. The report will be submitted individually, but there are several areas you are allowed to create together as a group.\n\nDeveloping a causal assessment of a model\nQuality control and exploratory data analysis\nEach of you will take a separate predictor and make/validate/assess the best SLR model you can. You will be predicting the coldest location at midnight on Monday May 1st in within State College borough/township,\nYou will assess the best MLR model you can\nGo wild with your final model choice, we can also look at non-regression options.\nEach group will get some temperature sensors to place in the spot you think is the coldest on May-1.\n\n\nYou are not being graded on the “best” model, you are being graded on creating a valid and sensible analysis with the information you have and with a write-up that clearly explains all techniques and results to a non-expert."
  },
  {
    "objectID": "in_S462_Tutorial4AdvancedMarkdown.html",
    "href": "in_S462_Tutorial4AdvancedMarkdown.html",
    "title": "T4: Advanced Markdown",
    "section": "",
    "text": "There are many ways to do this, with a FANTASTIC tutorial here if you get stuck:\nhttp://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/\n\nStep 1:\nGo find your picture. If it’s on the internet the easiest way is to right click on it and press “save as”, then save the jpeg or png directly into your project folder with an easy filename.\n\nStep 2:\nPlace your picture/photo into your project folder (e.g. your Lab 3 project folder).\n\nStep 3:\nMake a new code chunk. REMEMER TO ADD BLANK LINES ABOVE AND BELOW THE CODE CHUNK.\n\nStep 4\nInside the code chunk, use the knitr::include_graphics() command from the knitr package.\n\n\n\n\n\nYou’ll see I also added some code chunk options:\n\necho=FALSE : don’t show the code\nfig.align - ‘center’ : Centre align the photo when you press knit\nout.width - ‘60%’ : Make your photo smaller or larger on the page\nfig.cap - “your caption” : Add a caption (IN QUOTES). I used * to make mine italic.\n\nIf you run the code chunk by pressing the green arrow, you will see the picture, but not things like the caption.\nNow press knit and you should see the picture, caption and options, but not the code (if echo=FALSE is included)\n\nExample\nFor example, here’s an example on chipmunks. The chipmunk.webp file is inside my project folder. (note, the file type doesn’t matter but you have to type it)\nHere’s how it looks in my .Rmd file.\n\n\n\n\n\nand in the actual report:\n\n\n\n\n\nChipmunks are cool, image from: https://mymodernmet.com/chris-mcveigh-chipmunk-adventures\n\n\n\n\nFor more options see the tutorial: http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/\n\n\nIf you wish to add a video from youtube, you will need to install a new package called vembedr. Follow Tutorial 2 to install this package and add it to your library code chunk and run that code chunk.\nNow make a code chunk and use the embed_url command to embed a video of your choice from youtube/vimeo etc in your report. If you have issues, see teams."
  },
  {
    "objectID": "in_S462_Tutorial4AdvancedMarkdown.html#troubleshooting-yaml-code",
    "href": "in_S462_Tutorial4AdvancedMarkdown.html#troubleshooting-yaml-code",
    "title": "T4: Advanced Markdown",
    "section": "Troubleshooting YAML code",
    "text": "Troubleshooting YAML code\n\nNote, if you copy/paste this and it doesn’t work, sometimes the quote marks copy weirdly from the internet - try deleting and retyping the quotes.\n\nIf it still doesn’t work.. this might be because a space is missing (especially if you typed it out).\n\nEditing YAML code can be a pain. It is very case and space sensitive.For example, the spaces at the start of some lines are important and are created using the TAB KEY, not the space bar. There is one TAB key before html_notebook (which is now on a new line). There are two TAB KEYS before toc, toc_float, number_sections and theme.\n\n\nAlso try looking at the theme’s website e.g. google rmdformats add table of contents or similar.\nDon’t continue until you can make and view your html when you press knit. If it doesn’t work, ask for help before moving on"
  },
  {
    "objectID": "in_S462_Project3InitialEDA.html",
    "href": "in_S462_Project3InitialEDA.html",
    "title": "3. Initial EDA (this week)",
    "section": "",
    "text": "We have data! Now is the time to explore it and to make some initial models."
  },
  {
    "objectID": "in_S462_Project3InitialEDA.html#set-up",
    "href": "in_S462_Project3InitialEDA.html#set-up",
    "title": "3. Initial EDA (this week)",
    "section": "Set-up",
    "text": "Set-up\nYou can choose whether to use your RStudio cloud account or your own computers for this task (For RStudioCloud it seems that only one person can use a project effectively, so you’re welcome to use your shared space, but set up individual projects).\nYou can always copy/paste your final results together.\n\nEVERYONE (individually)\n\nSet up a project and get the data\n\nUse Tutorial 2 to create a new project (or use a sensible existing project). If you are using the shared cloud space, work in individual projects. Keep following the tutorial to create a new .RmD file.\nAt the very top, either create or edit a code chunk that looks like this. This will stop the annoying library packages loading when you knit. Here’s the text to copy/paste:\n\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message=FALSE,warning=FALSE)\n\n\n\n\n\n\n\n\nBelow that, create a new code chunk to load these libraries. You might need to install some using Tutorial 2.2.\n\n\nlibrary(readxl)  # read in data\nlibrary(sf)      # spatial\nlibrary(sp)      # spatial\nlibrary(raster)  # spatial\nlibrary(terra)   # spatial\nlibrary(tidyverse) # ALL\nlibrary(tmap)    # mapping\n\n\nGo to visual mode. Create a new header 1 called Exploratory Analysis\n\nClick this link to download the data: CLICK HERE. and put it in your project file. Use these commands to read it into R. The first one will create a data.frame (table) of your data. The second will create a “spatial version” that is easy to map. Press knit and check all is well.\n\n\nDataIn <- read_excel(\"STAT462_TrainingData.xlsx\")\nDataIn <- na.omit(DataIn)\nDataIn.sf <- st_as_sf(DataIn,coords=c( \"X\",\"Y\"),crs=\"EPSG:32617\")\n\n\nnames(DataIn)\n\n [1] \"Serial\"                  \"X\"                      \n [3] \"Y\"                       \"Elevation_1m\"           \n [5] \"Slope_1m\"                \"Roughness_1m\"           \n [7] \"Aspect_1m\"               \"LandCover_Code\"         \n [9] \"NCLD_Percent_Tree_Cover\" \"NCLD_Percent_Concrete\"  \n[11] \"Date\"                    \"Hour\"                   \n[13] \"Temp_F\"                  \"Light_Lux\"              \n[15] \"Notes\"                  \n\n\n\nOpen the data and take a look at it. (click on its name or put View(DataIn) IN THE CONSOLE\n\nYou should see the following columns\n\nSerial: the serial number of the item\nX and Y. The location of the item in X and Y metre coordinates (Long/Lat coordinates are poor over small areas, so I’m using the WGS84 17N / Pennsylvania North map projection (https://epsg.io/32617))\nElevation_1m : The elevation of the sensor to the closest metre from the USGS 1 meter Digital Elevation Model\nSlope_1m : The slope of the location where the sensor was placed, from the same USGS DEM\nAspect_1m : The aspect of the location where the sensor was placed., from the same USGS DEM\nRoughness_1m : The roughness of the location where the sensor was placed, from the same USGS DEM\nLandCover_Code: The NCLD landcover code for that location\nNCLD_Percent_Tree_Cover: The percent tree cover for that location\nNCLD_Percent_Concrete : The percent concrete at that location\nDate: Date of the measurement\nHour: Hour of the measurement\nTemp_F: The temperature measurement\nLight_Lux: The Light measurement\nNotes: Placement Notes\n\n\n\n\n\nGROUP challenges\nNow, there are several challenges that you can split as a group depending on your strengths.\n\nDescribing the data and the meta data. This means\n\nExplaining the unit of analysis, the population and the variable\nResearching and writing up why they have been “transformed” into UTM (hint: CLICK HERE)\nResearching and writing about each of the predictor variables (e.g. a few sentences about what it is etc, google and the links above should help, or ask me questions on Teams)\n\n\nMaking summary statistics and plots of the DataIn table. For example\n\nHow many sensors are there (hint, table command)\nAny missing data?\nFiltering the data to just one sensor, or one time of day (hint, this will really help: https://crd150.github.io/lab2.html#Data_Wrangling) and making a plot of the temperature over time, or say a histogram of the temps on a single day.\nFiltering the data in other ways and making exploratory plots and histograms.\n\n\nQuality controlling the data. For example,\n\nCan you trust all the readings at all times of day? Can you see examples of where there are issues.\nWhat about over all dates? Anything weird happening?\nIf you find things, decide whether you should keep or remove them AND WRITE DOWN WHAT YOU DID/CHANGED.\n\n\nUsing DataIn.sf Make some initial maps, especially of static variables that don’t change over time.\nYou could use QTM from the previous lab, for example\n\n\ntmap_mode(\"view\")\n\nqtm(DataIn.sf,\n            dots.col=\"NCLD_Percent_Tree_Cover\")+\n           tm_layout(legend.outside = TRUE)\n\n\n\n\n\n\n\nOr better still.. follow these instructions (https://psu-spatial.github.io/Geog364-2021/364Data_TutorialWranglePoint.html) or https://r-tmap.github.io/tmap-book/nutshell.html to make prettier ones.\n\nExplore the data.\n\nFinally, choose one different predictor variable each - and make a scatterplot to look at the impact on temperatures and a basic linear model.\n\nCritique your model so far, especially seeing if it visually fits the LINE assumptions.\nHow can we do better? Feel free to try other options and Lab 3 will help.."
  },
  {
    "objectID": "in_S462_Project3InitialEDA.html#combine-your-work-into-an-exploratory-data-analysis-part-of-your-report.",
    "href": "in_S462_Project3InitialEDA.html#combine-your-work-into-an-exploratory-data-analysis-part-of-your-report.",
    "title": "3. Initial EDA (this week)",
    "section": "Combine your work into an exploratory data analysis part of your report.",
    "text": "Combine your work into an exploratory data analysis part of your report."
  }
]