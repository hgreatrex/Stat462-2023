---
title: "1. Making teams"
---

# The main point - READ THIS!

```{r,warning=FALSE,error=FALSE,message=FALSE, include=FALSE}
rm(list=ls())
# Normally I would hide this but I wanted you to see the packages I used
library(knitr)
library(readxl)
library(stringr)
library(RColorBrewer)
library(factoextra)
library(ComplexHeatmap)
library(circlize)
library(DT)

```

DO NOT TAKE THIS SERIOUSLY - EVERYONE CAN FIT INTO ALL OF THESE GROUPS.

```{r, echo=FALSE,fig.cap="*Figure from https://xkcd.com/52/*",out.width="60%",fig.align='center'}

url <- "https://imgs.xkcd.com/comics/secret_worlds.jpg"
include_graphics(url)
```

None of this is part of our course. You do not have to reproduce it, learn it or do this in R. But it gets to the heart of regression... **you are just imagining models and seeing how the data best fits.**

I made this quiz in 10mins flat and the "model" was pretty hard to read. With that in mind, remember that those big sophisticated models that put us in groups on social media might be wrong too.. They're just guesses based on the imperfect information we feed them.

I also wanted you to see how cool these interactive markdown documents are.

------------------------------------------------------------------------

# What is machine learning

As we have are exploring in class, there are several types of machine learning.

-   In **supervised learning**, we know the "answer", or response values in our training data, so we then make a model using techniques such as regression to build a relationship between our response data and some predictor(s).

-   In **unsupervised learning**, we have no idea what the answer is. We are simply taking a load of data points, each with their own attributes, and letting a computer place them into "similar" clusters. Then when we get new data, we see which cluster it is part of.

```{r, echo=FALSE,fig.cap="*Figure from https://analystprep.com/study-notes/cfa-level-2/quantitative-method/supervised-machine-learning-unsupervised-machine-learning-deep-learning/*",out.width="90%",fig.align='center'}
# Define variable containing url
url <- "https://analystprep.com/study-notes/wp-content/uploads/2021/03/Img_12.jpg"
include_graphics(url)
```

## Using unsupervised learning for personalities..

There is definitely no "right" answer when it comes to human personality. We change from day to day and people make millions from the ability to get humans to work together. I certainly know nothing about you all, but I do know that groups work best when there are people able to fill certain roles.

In the past when I have taught group projects, people have either split via friendship, alphabetical order or the people sitting around them, which tends to leave many groups unbalanced. I was interested to see if a basic personality quiz and unsupervised machine learning could do better.

The other reason I wanted to see this is that my model is a very, very simple version of what the social internet does. [People often hear the myth that your phone "hears" what people say and shows you adverts. The likely reality is maybe even more disturbing.. that there are models so sophisticated that they can predict and market what you want before you realise you want it..](https://www.nytimes.com/wirecutter/blog/amazons-alexa-never-stops-listening-to-you/)

------------------------------------------------------------------------

# Setting up the study

The best models are very tailored to a specific end goal. My end goal was only to put you into effective working groups. So first of all, I thought about what roles might be useful and what types of teams tend to work well together.

I decided on these roles:

-   **Role Artist/Writer \|** Someone who takes pride in making the output look professional, who cares about color palettes or working out the right words to explain the output.

-   **Role Designer \|** Someone who cares about brainstorming, ideas and the big picture, who can make the links between the theory and the real life application.

-   **Role Coder \|** Someone who loves the code and the maths, who's not afraid to work through the tutorials and figure it out

-   **Role Coordinator \|** Someone who excels at managing projects, keeping track of deadlines and building a team community

I also guessed that there are a few general attributes that make people feel at home in teams. So I made two sliding scales; ignore my imperfect jargon!

-   **"Working Style" (Detail-oriented to Journey-Orientated).. \|** Detail orientated people were more likely to score highly on questions around being efficient or keeping to a plan. Journey orientated (journey before destination) people were more likely to score highly on questions around being easy going.

-   **"Group Style".. (Creative Chatty Group to Quieter Efficient Group)\|** These were questions around what type of group you said you preferred to work in.

So... in 10 minutes I made a very bad personality questionnaire where I tried to tailor my questions to these personality attributes (which I also dreamed up in 10 mins).

------------------------------------------------------------------------

# Data processing

## Step 1. Coding the quiz

I could have probably put your raw data into a model, but to make life easier on myself, I decided to assign a tag to each question with a corresponding "score". Some questions didn't really fit in the end, so I tagged those "ignore" and I tried a load of combinations before ending up with the exact roles above.

You can see my codes here, attached to each question number & option.

```{r}
# From the readxl package
Codes <- read_excel("Project1_PersonalityKey_Final.xlsx")

# This will print it nicely
Codes

```

------------------------------------------------------------------------

## Step 2. Quality Control

Because I didn't spend time setting up Canvas in advance, I then needed to find a way to match each of your answers to their equivalent score. This took a few steps:

1.  I saved your Canvas answers as an excel spreadsheet.
2.  R hates special characters like " ! , ' etc, so I selected the entire sheet then used find/replace to remove anything that I could think of. I did the same to the questions in the coding sheet so they would match.
3.  I then read the data into R. One column for each question. The object of analysis is a student.

```{r}
QuizData <- read_excel("Project 1_ CanvasAns_ReadyForR.xlsx")

# Showing the column names to keep the data more private and removing the second langauge data (column 14)
QuizData <- QuizData[-14]
```

Now I wanted to automatically change the canvas answers to the codes I made and I wanted to be general enough that if I changed a code, it could be easy to just re-run. This is messy coding! There are many more efficient ways to do it, but... it gets the job done. The output of this code is three tables where each person's answers/options are coded using my tags

```{r, collapse=TRUE}
# I'm now going to make three output datasets, one for just roles, 
# one for just group style and one for both
Roles <- QuizData
Styles <- QuizData


## Read in coding dataset
CodingKey <- read_excel("Project1_PersonalityKey_Final.xlsx")
CodingKey$UniqueCode <- paste(CodingKey$Question, CodingKey$Code,sep="_")

## Work out the unique questions. I made sure these match the column name
Unique_Qu <- unique(CodingKey$Question)

# For every question, find the location in both datasets and replace
# I'm certain there is a one line answer to this involving the merge command
# but this worked easiest for my brain

# For each question
for(n in 1:length(Unique_Qu)){
  # Find the column location for that question
  col_location <- which(names(QuizData) == Unique_Qu[n])
  
  # And get the unique question options from the Coding key
  QuestionKey <- CodingKey[CodingKey$Question ==  Unique_Qu[n] ,]
  
  # For every option
  for(option in 1:nrow(QuestionKey)){
    # For every person, because stringr was annoying
    for(row in 1:nrow(QuizData)){
      # Replace the question text with the tags
      Roles[row,col_location] <- str_replace_all(Roles[row,col_location],
                                                  QuestionKey$Text[option],
                                                  QuestionKey$Roles[option])
      
      Styles[row,col_location] <- str_replace_all(Styles[row,col_location],
                                                  QuestionKey$Text[option],
                                                  QuestionKey$Style[option])
      
    }
  }
}  

#adjust the column names, R doesnt like them starting with a number and I am too lazy to go back
names(Roles) <- paste("Q",names(Roles),sep="")
names(Styles) <- paste("Q",names(Styles),sep="")


```

OK, that's great - now each of your options has the correct code.. BUT I also need to assign the scores! For example if you said you hated art, I don't want you to rank highly as an artist. This code does that for the roles

```{r, collapse = TRUE}

# Get each person's identifier. CHANGE THIS HLG
RoleCodes <- Roles[,1:4]

# Make new blank columns for each CODE rather than question e.g. artist role
for(col in 1:length(unique(CodingKey$Roles))){
  RoleCodes[,4+col] <- NA
  names(RoleCodes)[4+col] <- unique(CodingKey$Roles)[col]
}
cols <- 5:ncol(Roles)
Roles$AllAns <- apply( Roles[ , cols ] , 1 , paste , collapse = "," )

# For each person and each Meta Code
for(p in 1:nrow(RoleCodes)){
  #This splits all your answer tags into a frequency table
  tmp <- data.frame(table(str_split(Roles$AllAns[p],",")[[1]]))
  for(n in 1:nrow(tmp)){
    newcol <- which(names(RoleCodes) %in% tmp[n,1])
    RoleCodes[p,newcol] <- tmp[n,2]
  }
  
}


```

and the same for the working style.. I did say it was messy code!

```{r, collapse = TRUE}

# Get each person's identifier. CHANGE THIS HLG
StyleCodes <- Styles[,1:4]

# Make new blank columns for each CODE rather than question e.g. artist Style
for(col in 1:length(unique(CodingKey$Style))){
  StyleCodes[,4+col] <- NA
  names(StyleCodes)[4+col] <- unique(CodingKey$Style)[col]
}
cols <- 5:ncol(Styles)
Styles$AllAns <- apply( Styles[ , cols ] , 1 , paste , collapse = "," )

# For each person and each Meta Code
for(p in 1:nrow(StyleCodes)){
  tmp <- data.frame(table(str_split(Styles$AllAns[p],",")[[1]]))
  for(n in 1:nrow(tmp)){
    newcol <- which(names(StyleCodes) %in% tmp[n,1])
    StyleCodes[p,newcol] <- tmp[n,2]
  }
  
}

# manually stick them together into one
CodedData <- cbind(RoleCodes[,c(1:4,6:9)],StyleCodes[,6:7])

# and replace any NA's with 0 (e.g. people didn't choose enough to give an opinion)
CodedData[is.na(CodedData)==TRUE] <- 0



```

OK! Here are the results. You all shared your introduction posts with each other, but to preserve privacy I am displaying them as your email ID. For later plots, I will use anonymous tags.

REMEMBER, THIS IS JUST BASED ON MY BIASED INTERPRETATION OF QUICK QUESTIONS AND TAGGING. IT'S NOT "TRUTH". For example, maybe there is some cultural or implicit bias in my questions or the way I phrased them so that some students interpreted them differently..

```{r}
CodedData[,c(2,5:10)]
```

------------------------------------------------------------------------

# Exploratory Analysis

I admit, getting the data in order took longer than I expected, so i'm using a very simple unsupervised technique called k-means clustering.

I first wanted to assign people to a role

```{r}

# and I'm going to rank the answers e.g. rather than using raw numbers I'm saying "most artist score" vs "least artist score"

ScaledData <- scale(CodedData[,c(5:10)])
row.names(ScaledData) <- CodedData[,4] 
densityHeatmap(ScaledData)
```

Finally results! We can see that for many of the role, people tend to categorise themselves in a binary way e.g. for Role_Modeller, you can clearly see the people who answered "Hate progamming vs Love Programming". A few of the categories are less clear, for example artist/writer, which could reflect my questions or that really everyone is pretty creative..

```{r}
Heatmap(ScaledData, name ="Group Type", col = colorRamp2(c(-2, 0, 2), brewer.pal(n=3, name="RdBu")),
        km = 2, split =  CodedData$GroupVibe)

```

This is also interesting, I split my data by group type (high values are more chatty/excited, low values are more reserved and less keen).

You can see that there are distinct clusters in some of the roles. For example people who scored highly on "designer" were more likely to also score highly on working in groups. Again this MIGHT be a true effect, or a result of my imperfect questions.

# Modelling

Note, I should have really used a hierarchical set up, where "Role" had 4 sub groups, but it means rearranging the data and writing this is a lot more involved than I expected! So here's my 2023 first draft attempt.

To make R studio cloud work, we need to be in groups of 4. So I want to do this in two steps.\
- Step 1, Split you all hopefully into similar groups - Step 2, Look at roles within the groups.

Let's start with the roles

```{r}

# Just choose the role columns
StyleData <- scale(CodedData[,c(9:10)])

fviz_nbclust(StyleData, kmeans, method = "wss")
fviz_nbclust(StyleData, kmeans, method = "silhouette")

```

This gives me a sense that there isn't a huge data signal in an optimal number of clusters. There's a slight elbow at 4 groups, but the sillouette plot isn't convincing me. This is in part due to not much data. See [this link for a nice interpretation](https://towardsdatascience.com/elbow-method-is-not-sufficient-to-find-best-k-in-k-means-clustering-fc820da0631d) or look up a fviz_nbclust tutorial.

```{r}
fit <- kmeans(StyleData, centers = 4, nstart = 25)
fviz_cluster(fit, data = StyleData)
print(fit)

CodedData$GroupCode <- fit$cluster

```

```{r}

Heatmap(fit$centers, name ="Score", 
        col = colorRamp2(c(-2, 0, 2), brewer.pal(n=3, name="RdBu")), 
        km = 2)

```

OK, so the x axis shows the two variables we were sorting

-   **"Working Style" (Detail-oriented to Journey-Orientated).. \|** Detail orientated people were more likely to score highly on questions around being efficient or keeping to a plan. Journey orientated (journey before destination) people were more likely to score highly on questions around being easy going.

-   **"Group Style".. (Creative Chatty Group to Quieter Efficient Group)\|** These were questions around what type of group you said you preferred to work in. For example, maybe English is your second langauge and working in groups is stressful. Or you're simply someone who prefers to work alone.

And the y axis shows the four groups:

-   GroupType 1 Detail orientated but quieter/solo work (5 people)
-   GroupType 2 Happy either way (6 people)
-   GroupType 3 Loves groups, more relaxed (14 people)
-   GroupType 4 Relaxed but not so keen on group work (17 people)

------------------------------------------------------------------------

Now lets look at the roles

```{r}

# Just choose the role columns
RoleData <- scale(CodedData[,c(5:8)])

fviz_nbclust(RoleData, kmeans, method = "wss")
fviz_nbclust(RoleData, kmeans, method = "silhouette")

```

This gives me a sense that there isn't a huge data signal in an optimal number of clusters but that maybe 8 clusters is optimal. See [this link for a nice interpretation](https://towardsdatascience.com/elbow-method-is-not-sufficient-to-find-best-k-in-k-means-clustering-fc820da0631d) or look up a fviz_nbclust tutorial.

For now, I want to make my life easy so I can focus on actually teaching you all regression. I first split you into four groups using kmeans clustering.

```{r}
fit <- kmeans(RoleData, centers = 4, nstart = 25)
fviz_cluster(fit, data = RoleData)
print(fit)

CodedData$RoleCode <- fit$cluster


```

You can more easily see the properties of the four clusters here:

-   Group 1: Designer/Artists (7 people)
-   Group 2: Coordinators (15 people)
-   Group 3: Coordinator/Modellers (7 people)
-   Group 4: Bit of everything, but loves art especially. less keen on brainstorming (13 people)

```{r}

Heatmap(fit$centers, name ="Group Type", 
        col = colorRamp2(c(-2, 0, 2), brewer.pal(n=3, name="RdBu")),
        km = 2)

```

And from this, because I'm on line 400 of code, I'm going use those results to then manually assign you to groups, where each group has a range of roles but you have similar group types.

I will take another attempt later in the semester to be more sophisticated about the modelling!

Here is the summary of the final two sets of classifications and you can use the keys above to interpret your own answers and whether it rings true or not.

```{r}
CodedData[,c(2,5:12)]
```
